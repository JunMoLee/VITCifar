{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logdir</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>n_parameters</th>\n",
       "      <th>runtime</th>\n",
       "      <th>use_for_next</th>\n",
       "      <th>amp</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>conv_ratio</th>\n",
       "      <th>depth</th>\n",
       "      <th>dim</th>\n",
       "      <th>dropout</th>\n",
       "      <th>emb_dropout</th>\n",
       "      <th>epochs</th>\n",
       "      <th>heads</th>\n",
       "      <th>linformer</th>\n",
       "      <th>lr</th>\n",
       "      <th>mlp_dim</th>\n",
       "      <th>n_out_convs</th>\n",
       "      <th>num_workers</th>\n",
       "      <th>patch_size</th>\n",
       "      <th>rel_pos</th>\n",
       "      <th>rel_pos_mul</th>\n",
       "      <th>squeeze_conv</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>n_mid_convs</th>\n",
       "      <th>sep_conv</th>\n",
       "      <th>resume_dir</th>\n",
       "      <th>cnn_baseline</th>\n",
       "      <th>mlp_dim_mul</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p4-e100</td>\n",
       "      <td>0.7180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p2-e100</td>\n",
       "      <td>0.7163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p2-e300</td>\n",
       "      <td>0.7633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p4-e100-model2</td>\n",
       "      <td>0.7179</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p4-e100-relpos</td>\n",
       "      <td>0.7545</td>\n",
       "      <td>1901578.0</td>\n",
       "      <td>1421.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>p4-e100-relpos-d0</td>\n",
       "      <td>0.7610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>p4-e100-relpos-nconv1</td>\n",
       "      <td>0.8104</td>\n",
       "      <td>2492170.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>p4-e100-relpos-nconv2</td>\n",
       "      <td>0.8371</td>\n",
       "      <td>3082762.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>p4-e100-relpos-nconv2-squeezeconv</td>\n",
       "      <td>0.8437</td>\n",
       "      <td>3099402.0</td>\n",
       "      <td>2037.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>p4-e100-relpos-relposmul-nconv2-squeezeconv</td>\n",
       "      <td>0.8406</td>\n",
       "      <td>3102102.0</td>\n",
       "      <td>2180.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>out_gelu</td>\n",
       "      <td>0.8493</td>\n",
       "      <td>3099402.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>linformer</td>\n",
       "      <td>0.8514</td>\n",
       "      <td>2418186.0</td>\n",
       "      <td>1676.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>e300</td>\n",
       "      <td>0.8748</td>\n",
       "      <td>2418186.0</td>\n",
       "      <td>5010.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>convratio0.5</td>\n",
       "      <td>0.8610</td>\n",
       "      <td>2664202.0</td>\n",
       "      <td>2053.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>512.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>doubleconv</td>\n",
       "      <td>0.8708</td>\n",
       "      <td>3107722.0</td>\n",
       "      <td>2282.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>512.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>nmidconv5</td>\n",
       "      <td>0.8829</td>\n",
       "      <td>4438282.0</td>\n",
       "      <td>2795.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>512.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>nooutcovs</td>\n",
       "      <td>0.8804</td>\n",
       "      <td>3257098.0</td>\n",
       "      <td>2593.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>wd0.00001</td>\n",
       "      <td>0.8638</td>\n",
       "      <td>3257098.0</td>\n",
       "      <td>2627.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dim512-mlpdim1024-depth6-heads8</td>\n",
       "      <td>0.9006</td>\n",
       "      <td>24917770.0</td>\n",
       "      <td>9632.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>6.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>p2</td>\n",
       "      <td>0.9157</td>\n",
       "      <td>3346186.0</td>\n",
       "      <td>6149.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>p1</td>\n",
       "      <td>0.9129</td>\n",
       "      <td>3737098.0</td>\n",
       "      <td>26625.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>p2-nmidconv10</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>5563786.0</td>\n",
       "      <td>8585.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sepconv</td>\n",
       "      <td>0.9126</td>\n",
       "      <td>2271306.0</td>\n",
       "      <td>11138.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>3.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>dim512-mlpdim512-depth6-heads8</td>\n",
       "      <td>0.9364</td>\n",
       "      <td>39397130.0</td>\n",
       "      <td>33512.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>6.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>logs/dim512-mlpdim512-depth6-heads8/best.pth</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>resnet18</td>\n",
       "      <td>0.9381</td>\n",
       "      <td>11173962.0</td>\n",
       "      <td>2917.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>convratio1.0</td>\n",
       "      <td>0.9313</td>\n",
       "      <td>11197009.0</td>\n",
       "      <td>10392.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>512.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>convratio0.875</td>\n",
       "      <td>0.9355</td>\n",
       "      <td>10770094.0</td>\n",
       "      <td>14313.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>convratio0.75</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>11150254.0</td>\n",
       "      <td>14958.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>3.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>convratio0.625</td>\n",
       "      <td>0.9373</td>\n",
       "      <td>10811674.0</td>\n",
       "      <td>14462.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.625</td>\n",
       "      <td>3.0</td>\n",
       "      <td>384.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         logdir  accuracy  n_parameters  \\\n",
       "0                                       p4-e100    0.7180           NaN   \n",
       "1                                       p2-e100    0.7163           NaN   \n",
       "2                                       p2-e300    0.7633           NaN   \n",
       "3                                p4-e100-model2    0.7179           NaN   \n",
       "4                                p4-e100-relpos    0.7545     1901578.0   \n",
       "5                             p4-e100-relpos-d0    0.7610           NaN   \n",
       "6                         p4-e100-relpos-nconv1    0.8104     2492170.0   \n",
       "7                         p4-e100-relpos-nconv2    0.8371     3082762.0   \n",
       "8             p4-e100-relpos-nconv2-squeezeconv    0.8437     3099402.0   \n",
       "9   p4-e100-relpos-relposmul-nconv2-squeezeconv    0.8406     3102102.0   \n",
       "10                                     out_gelu    0.8493     3099402.0   \n",
       "11                                    linformer    0.8514     2418186.0   \n",
       "12                                         e300    0.8748     2418186.0   \n",
       "13                                 convratio0.5    0.8610     2664202.0   \n",
       "14                                   doubleconv    0.8708     3107722.0   \n",
       "15                                    nmidconv5    0.8829     4438282.0   \n",
       "16                                    nooutcovs    0.8804     3257098.0   \n",
       "17                                    wd0.00001    0.8638     3257098.0   \n",
       "18              dim512-mlpdim1024-depth6-heads8    0.9006    24917770.0   \n",
       "19                                           p2    0.9157     3346186.0   \n",
       "20                                           p1    0.9129     3737098.0   \n",
       "21                                p2-nmidconv10    0.9250     5563786.0   \n",
       "22                                      sepconv    0.9126     2271306.0   \n",
       "23               dim512-mlpdim512-depth6-heads8    0.9364    39397130.0   \n",
       "24                                     resnet18    0.9381    11173962.0   \n",
       "25                                 convratio1.0    0.9313    11197009.0   \n",
       "26                               convratio0.875    0.9355    10770094.0   \n",
       "27                                convratio0.75    0.9387    11150254.0   \n",
       "28                               convratio0.625    0.9373    10811674.0   \n",
       "\n",
       "    runtime use_for_next  amp  batch_size  conv_ratio  depth    dim  dropout  \\\n",
       "0       NaN         True  NaN         NaN         NaN    NaN    NaN      NaN   \n",
       "1       NaN        False  NaN         NaN         NaN    NaN    NaN      NaN   \n",
       "2       NaN        False  NaN         NaN         NaN    NaN    NaN      NaN   \n",
       "3       NaN         True  NaN         NaN         NaN    NaN    NaN      NaN   \n",
       "4    1421.0         True  NaN         NaN         NaN    NaN    NaN      NaN   \n",
       "5       NaN        False  NaN         NaN         NaN    NaN    NaN      NaN   \n",
       "6       NaN         True  NaN         NaN         NaN    NaN    NaN      NaN   \n",
       "7       NaN         True  NaN         NaN         NaN    NaN    NaN      NaN   \n",
       "8    2037.0        False  NaN         NaN         NaN    NaN    NaN      NaN   \n",
       "9    2180.0          NaN  NaN         NaN         NaN    NaN    NaN      NaN   \n",
       "10   2012.0         True  NaN         NaN         NaN    NaN    NaN      NaN   \n",
       "11   1676.0         True  NaN         NaN         NaN    NaN    NaN      NaN   \n",
       "12   5010.0        False  NaN         NaN         NaN    NaN    NaN      NaN   \n",
       "13   2053.0          NaN  0.0        64.0       0.500    3.0  256.0      0.1   \n",
       "14   2282.0          NaN  0.0        64.0       0.500    3.0  256.0      0.1   \n",
       "15   2795.0          NaN  0.0        64.0       0.500    3.0  256.0      0.1   \n",
       "16   2593.0         True  0.0        64.0       0.500    3.0  256.0      0.1   \n",
       "17   2627.0          NaN  0.0        64.0       0.500    3.0  256.0      0.1   \n",
       "18   9632.0          NaN  0.0        64.0       0.500    6.0  512.0      0.1   \n",
       "19   6149.0          NaN  0.0        64.0       0.500    3.0  256.0      0.1   \n",
       "20  26625.0          NaN  0.0        64.0       0.500    3.0  256.0      0.1   \n",
       "21   8585.0         True  0.0        64.0       0.500    3.0  256.0      0.1   \n",
       "22  11138.0        False  0.0        64.0       0.750    3.0  256.0      0.1   \n",
       "23  33512.0         True  0.0        64.0       0.500    6.0  512.0      0.1   \n",
       "24   2917.0          NaN  0.0        64.0       1.000    3.0  100.0      0.1   \n",
       "25  10392.0          NaN  0.0        64.0       1.000    3.0  251.0      0.1   \n",
       "26  14313.0          NaN  0.0        64.0       0.875    3.0  288.0      0.1   \n",
       "27  14958.0          NaN  0.0        64.0       0.750    3.0  336.0      0.1   \n",
       "28  14462.0          NaN  0.0        64.0       0.625    3.0  384.0      0.1   \n",
       "\n",
       "    emb_dropout  epochs  heads  linformer   lr  mlp_dim  n_out_convs  \\\n",
       "0           NaN     NaN    NaN        NaN  NaN      NaN          NaN   \n",
       "1           NaN     NaN    NaN        NaN  NaN      NaN          NaN   \n",
       "2           NaN     NaN    NaN        NaN  NaN      NaN          NaN   \n",
       "3           NaN     NaN    NaN        NaN  NaN      NaN          NaN   \n",
       "4           NaN     NaN    NaN        NaN  NaN      NaN          NaN   \n",
       "5           NaN     NaN    NaN        NaN  NaN      NaN          NaN   \n",
       "6           NaN     NaN    NaN        NaN  NaN      NaN          NaN   \n",
       "7           NaN     NaN    NaN        NaN  NaN      NaN          NaN   \n",
       "8           NaN     NaN    NaN        NaN  NaN      NaN          NaN   \n",
       "9           NaN     NaN    NaN        NaN  NaN      NaN          NaN   \n",
       "10          NaN     NaN    NaN        NaN  NaN      NaN          NaN   \n",
       "11          NaN     NaN    NaN        NaN  NaN      NaN          NaN   \n",
       "12          NaN     NaN    NaN        NaN  NaN      NaN          NaN   \n",
       "13          0.1   100.0    4.0        1.0  0.1    512.0          2.0   \n",
       "14          0.1   100.0    4.0        1.0  0.1    512.0          2.0   \n",
       "15          0.1   100.0    4.0        1.0  0.1    512.0          2.0   \n",
       "16          0.1   100.0    4.0        1.0  0.1    512.0          0.0   \n",
       "17          0.1   100.0    4.0        1.0  0.1    512.0          0.0   \n",
       "18          0.1   100.0    8.0        1.0  0.1   1024.0          0.0   \n",
       "19          0.1   100.0    4.0        1.0  0.1    512.0          0.0   \n",
       "20          0.1   100.0    4.0        1.0  0.1    512.0          0.0   \n",
       "21          0.1   100.0    4.0        1.0  0.1    512.0          0.0   \n",
       "22          0.1   100.0    4.0        1.0  0.1    512.0          0.0   \n",
       "23          0.1   100.0    8.0        1.0  0.1    512.0          0.0   \n",
       "24          0.1   100.0    4.0      128.0  0.1    512.0          0.0   \n",
       "25          0.1   100.0    4.0        0.0  0.1    512.0          0.0   \n",
       "26          0.1   100.0    4.0        0.0  0.1      NaN          0.0   \n",
       "27          0.1   100.0    4.0        0.0  0.1      NaN          0.0   \n",
       "28          0.1   100.0    4.0        0.0  0.1      NaN          0.0   \n",
       "\n",
       "    num_workers  patch_size  rel_pos  rel_pos_mul  squeeze_conv  weight_decay  \\\n",
       "0           NaN         NaN      NaN          NaN           NaN           NaN   \n",
       "1           NaN         NaN      NaN          NaN           NaN           NaN   \n",
       "2           NaN         NaN      NaN          NaN           NaN           NaN   \n",
       "3           NaN         NaN      NaN          NaN           NaN           NaN   \n",
       "4           NaN         NaN      NaN          NaN           NaN           NaN   \n",
       "5           NaN         NaN      NaN          NaN           NaN           NaN   \n",
       "6           NaN         NaN      NaN          NaN           NaN           NaN   \n",
       "7           NaN         NaN      NaN          NaN           NaN           NaN   \n",
       "8           NaN         NaN      NaN          NaN           NaN           NaN   \n",
       "9           NaN         NaN      NaN          NaN           NaN           NaN   \n",
       "10          NaN         NaN      NaN          NaN           NaN           NaN   \n",
       "11          NaN         NaN      NaN          NaN           NaN           NaN   \n",
       "12          NaN         NaN      NaN          NaN           NaN           NaN   \n",
       "13          4.0         4.0      1.0          0.0           1.0       0.00010   \n",
       "14          4.0         4.0      1.0          0.0           1.0       0.00010   \n",
       "15          4.0         4.0      1.0          0.0           1.0       0.00010   \n",
       "16          4.0         4.0      1.0          0.0           1.0       0.00010   \n",
       "17          4.0         4.0      1.0          0.0           1.0       0.00001   \n",
       "18          4.0         4.0      1.0          0.0           1.0       0.00010   \n",
       "19          4.0         2.0      1.0          0.0           1.0       0.00010   \n",
       "20          4.0         1.0      1.0          0.0           1.0       0.00010   \n",
       "21          4.0         2.0      1.0          0.0           1.0       0.00010   \n",
       "22          4.0         2.0      1.0          0.0           1.0       0.00010   \n",
       "23          4.0         2.0      1.0          0.0           1.0       0.00010   \n",
       "24          4.0         2.0      1.0          0.0           1.0       0.00010   \n",
       "25          4.0         2.0      1.0          0.0           1.0       0.00010   \n",
       "26          4.0         2.0      1.0          0.0           1.0       0.00010   \n",
       "27          4.0         2.0      1.0          0.0           1.0       0.00010   \n",
       "28          4.0         2.0      1.0          0.0           1.0       0.00010   \n",
       "\n",
       "    n_mid_convs  sep_conv                                    resume_dir  \\\n",
       "0           NaN       NaN                                           NaN   \n",
       "1           NaN       NaN                                           NaN   \n",
       "2           NaN       NaN                                           NaN   \n",
       "3           NaN       NaN                                           NaN   \n",
       "4           NaN       NaN                                           NaN   \n",
       "5           NaN       NaN                                           NaN   \n",
       "6           NaN       NaN                                           NaN   \n",
       "7           NaN       NaN                                           NaN   \n",
       "8           NaN       NaN                                           NaN   \n",
       "9           NaN       NaN                                           NaN   \n",
       "10          NaN       NaN                                           NaN   \n",
       "11          NaN       NaN                                           NaN   \n",
       "12          NaN       NaN                                           NaN   \n",
       "13          NaN       NaN                                           NaN   \n",
       "14          NaN       NaN                                           NaN   \n",
       "15          5.0       NaN                                           NaN   \n",
       "16          5.0       NaN                                           NaN   \n",
       "17          5.0       NaN                                           NaN   \n",
       "18          5.0       NaN                                           NaN   \n",
       "19          5.0       NaN                                           NaN   \n",
       "20          5.0       NaN                                           NaN   \n",
       "21         10.0       NaN                                           NaN   \n",
       "22         10.0       1.0                                           NaN   \n",
       "23         10.0       0.0  logs/dim512-mlpdim512-depth6-heads8/best.pth   \n",
       "24         10.0       0.0                                           NaN   \n",
       "25          6.0       0.0                                           NaN   \n",
       "26          6.0       0.0                                           NaN   \n",
       "27          6.0       0.0                                           NaN   \n",
       "28          6.0       0.0                                           NaN   \n",
       "\n",
       "    cnn_baseline  mlp_dim_mul  \n",
       "0            NaN          NaN  \n",
       "1            NaN          NaN  \n",
       "2            NaN          NaN  \n",
       "3            NaN          NaN  \n",
       "4            NaN          NaN  \n",
       "5            NaN          NaN  \n",
       "6            NaN          NaN  \n",
       "7            NaN          NaN  \n",
       "8            NaN          NaN  \n",
       "9            NaN          NaN  \n",
       "10           NaN          NaN  \n",
       "11           NaN          NaN  \n",
       "12           NaN          NaN  \n",
       "13           NaN          NaN  \n",
       "14           NaN          NaN  \n",
       "15           NaN          NaN  \n",
       "16           NaN          NaN  \n",
       "17           NaN          NaN  \n",
       "18           NaN          NaN  \n",
       "19           NaN          NaN  \n",
       "20           NaN          NaN  \n",
       "21           NaN          NaN  \n",
       "22           NaN          NaN  \n",
       "23           NaN          NaN  \n",
       "24           1.0          NaN  \n",
       "25           0.0          NaN  \n",
       "26           0.0          2.0  \n",
       "27           0.0          2.0  \n",
       "28           0.0          2.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 999\n",
    "pd.read_csv('history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train Samples: 50000 | # Val Samples: 10000\n",
      "# Parameters: 11173962\n",
      "EPOCH: 0 | LRs: {0.0040000000000000036}\n",
      "(trn) LOSS: 1.902702 | METRIC: 0.30402\n",
      "(val) LOSS: 1.663886 | METRIC: 0.3928\n",
      "Runtime: 29\n",
      "EPOCH: 1 | LRs: {0.09999999995883255}\n",
      "(trn) LOSS: 1.528326 | METRIC: 0.43954\n",
      "(val) LOSS: 2.343028 | METRIC: 0.4512\n",
      "Runtime: 28\n",
      "EPOCH: 2 | LRs: {0.09997476280359487}\n",
      "(trn) LOSS: 1.296792 | METRIC: 0.53252\n",
      "(val) LOSS: 1.274193 | METRIC: 0.592\n",
      "EPOCH: 3 | LRs: {0.09989920549977627}\n",
      "(trn) LOSS: 1.156011 | METRIC: 0.58782\n",
      "(val) LOSS: 1.458265 | METRIC: 0.5756\n",
      "EPOCH: 4 | LRs: {0.09977340412717695}\n",
      "(trn) LOSS: 1.04108 | METRIC: 0.62992\n",
      "(val) LOSS: 1.468753 | METRIC: 0.6765\n",
      "EPOCH: 5 | LRs: {0.09959748535711543}\n",
      "(trn) LOSS: 0.947431 | METRIC: 0.66568\n",
      "(val) LOSS: 1.005049 | METRIC: 0.703\n",
      "EPOCH: 6 | LRs: {0.09937162632488114}\n",
      "(trn) LOSS: 0.875646 | METRIC: 0.6907\n",
      "(val) LOSS: 1.05916 | METRIC: 0.7109\n",
      "EPOCH: 7 | LRs: {0.09909605445137433}\n",
      "(trn) LOSS: 0.828177 | METRIC: 0.71108\n",
      "(val) LOSS: 0.628299 | METRIC: 0.7307\n",
      "EPOCH: 8 | LRs: {0.09877104721411233}\n",
      "(trn) LOSS: 0.782261 | METRIC: 0.7289\n",
      "(val) LOSS: 0.88108 | METRIC: 0.7091\n",
      "EPOCH: 9 | LRs: {0.09839693186783342}\n",
      "(trn) LOSS: 0.744783 | METRIC: 0.7422\n",
      "(val) LOSS: 0.600343 | METRIC: 0.7608\n",
      "EPOCH: 10 | LRs: {0.0979740851149789}\n",
      "(trn) LOSS: 0.716807 | METRIC: 0.75214\n",
      "(val) LOSS: 1.049025 | METRIC: 0.7629\n",
      "EPOCH: 11 | LRs: {0.09750293272638572}\n",
      "(trn) LOSS: 0.690583 | METRIC: 0.75994\n",
      "(val) LOSS: 0.486381 | METRIC: 0.7589\n",
      "EPOCH: 12 | LRs: {0.09698394911257129}\n",
      "(trn) LOSS: 0.668284 | METRIC: 0.7688\n",
      "(val) LOSS: 0.931486 | METRIC: 0.6739\n",
      "EPOCH: 13 | LRs: {0.09641765684604235}\n",
      "(trn) LOSS: 0.654948 | METRIC: 0.77126\n",
      "(val) LOSS: 0.727083 | METRIC: 0.759\n",
      "EPOCH: 14 | LRs: {0.0958046261351088}\n",
      "(trn) LOSS: 0.636277 | METRIC: 0.77836\n",
      "(val) LOSS: 0.652811 | METRIC: 0.7442\n",
      "EPOCH: 15 | LRs: {0.09514547424973213}\n",
      "(trn) LOSS: 0.626945 | METRIC: 0.78238\n",
      "(val) LOSS: 1.328006 | METRIC: 0.7676\n",
      "EPOCH: 16 | LRs: {0.09444086489998703}\n",
      "(trn) LOSS: 0.604833 | METRIC: 0.7905\n",
      "(val) LOSS: 0.542378 | METRIC: 0.8005\n",
      "EPOCH: 17 | LRs: {0.0936915075677615}\n",
      "(trn) LOSS: 0.588645 | METRIC: 0.7958\n",
      "(val) LOSS: 0.463351 | METRIC: 0.7926\n",
      "EPOCH: 18 | LRs: {0.09289815679236878}\n",
      "(trn) LOSS: 0.579351 | METRIC: 0.7998\n",
      "(val) LOSS: 0.185137 | METRIC: 0.7848\n",
      "EPOCH: 19 | LRs: {0.09206161141079022}\n",
      "(trn) LOSS: 0.569612 | METRIC: 0.80178\n",
      "(val) LOSS: 0.63609 | METRIC: 0.7979\n",
      "EPOCH: 20 | LRs: {0.09118271375331419}\n",
      "(trn) LOSS: 0.565653 | METRIC: 0.8052\n",
      "(val) LOSS: 0.831538 | METRIC: 0.7937\n",
      "EPOCH: 21 | LRs: {0.09026234879538077}\n",
      "(trn) LOSS: 0.551435 | METRIC: 0.80916\n",
      "(val) LOSS: 0.969261 | METRIC: 0.8005\n",
      "EPOCH: 22 | LRs: {0.08930144326648662}\n",
      "(trn) LOSS: 0.546115 | METRIC: 0.80912\n",
      "(val) LOSS: 1.577904 | METRIC: 0.8\n",
      "EPOCH: 23 | LRs: {0.08830096471704685}\n",
      "(trn) LOSS: 0.536285 | METRIC: 0.81334\n",
      "(val) LOSS: 0.362636 | METRIC: 0.7999\n",
      "EPOCH: 24 | LRs: {0.08726192054415381}\n",
      "(trn) LOSS: 0.528565 | METRIC: 0.81546\n",
      "(val) LOSS: 0.417603 | METRIC: 0.8221\n",
      "EPOCH: 25 | LRs: {0.08618535697721363}\n",
      "(trn) LOSS: 0.51998 | METRIC: 0.81982\n",
      "(val) LOSS: 1.072719 | METRIC: 0.8024\n",
      "EPOCH: 26 | LRs: {0.0850723580244818}\n",
      "(trn) LOSS: 0.51506 | METRIC: 0.82108\n",
      "(val) LOSS: 0.220289 | METRIC: 0.728\n",
      "EPOCH: 27 | LRs: {0.08392404438155886}\n",
      "(trn) LOSS: 0.507383 | METRIC: 0.82282\n",
      "(val) LOSS: 0.349577 | METRIC: 0.7582\n",
      "EPOCH: 28 | LRs: {0.08274157230294484}\n",
      "(trn) LOSS: 0.502837 | METRIC: 0.82488\n",
      "(val) LOSS: 0.732423 | METRIC: 0.8218\n",
      "EPOCH: 29 | LRs: {0.08152613243778901}\n",
      "(trn) LOSS: 0.497866 | METRIC: 0.8276\n",
      "(val) LOSS: 0.784346 | METRIC: 0.8157\n",
      "EPOCH: 30 | LRs: {0.08027894863100724}\n",
      "(trn) LOSS: 0.488686 | METRIC: 0.8315\n",
      "(val) LOSS: 0.260873 | METRIC: 0.8219\n",
      "EPOCH: 31 | LRs: {0.07900127669097362}\n",
      "(trn) LOSS: 0.487619 | METRIC: 0.82992\n",
      "(val) LOSS: 0.520308 | METRIC: 0.8189\n",
      "EPOCH: 32 | LRs: {0.07769440312502822}\n",
      "(trn) LOSS: 0.48531 | METRIC: 0.83034\n",
      "(val) LOSS: 0.733149 | METRIC: 0.8166\n",
      "EPOCH: 33 | LRs: {0.07635964384407298}\n",
      "(trn) LOSS: 0.477393 | METRIC: 0.83248\n",
      "(val) LOSS: 0.629927 | METRIC: 0.8328\n",
      "EPOCH: 34 | LRs: {0.07499834283756114}\n",
      "(trn) LOSS: 0.47833 | METRIC: 0.83164\n",
      "(val) LOSS: 0.609586 | METRIC: 0.8241\n",
      "EPOCH: 35 | LRs: {0.07361187082021371}\n",
      "(trn) LOSS: 0.466465 | METRIC: 0.8373\n",
      "(val) LOSS: 0.83493 | METRIC: 0.828\n",
      "EPOCH: 36 | LRs: {0.07220162385182598}\n",
      "(trn) LOSS: 0.466471 | METRIC: 0.83876\n",
      "(val) LOSS: 0.529061 | METRIC: 0.8536\n",
      "EPOCH: 37 | LRs: {0.07076902193155353}\n",
      "(trn) LOSS: 0.455866 | METRIC: 0.84102\n",
      "(val) LOSS: 0.557797 | METRIC: 0.8134\n",
      "EPOCH: 38 | LRs: {0.06931550756809367}\n",
      "(trn) LOSS: 0.454246 | METRIC: 0.84342\n",
      "(val) LOSS: 0.351281 | METRIC: 0.8269\n",
      "EPOCH: 39 | LRs: {0.06784254432720126}\n",
      "(trn) LOSS: 0.45258 | METRIC: 0.84228\n",
      "(val) LOSS: 0.114383 | METRIC: 0.8565\n",
      "EPOCH: 40 | LRs: {0.06635161535800212}\n",
      "(trn) LOSS: 0.441148 | METRIC: 0.84498\n",
      "(val) LOSS: 0.503846 | METRIC: 0.8557\n",
      "EPOCH: 41 | LRs: {0.0648442218995876}\n",
      "(trn) LOSS: 0.441575 | METRIC: 0.84644\n",
      "(val) LOSS: 0.612379 | METRIC: 0.8455\n",
      "EPOCH: 42 | LRs: {0.06332188176939406}\n",
      "(trn) LOSS: 0.43671 | METRIC: 0.84786\n",
      "(val) LOSS: 0.210275 | METRIC: 0.8339\n",
      "EPOCH: 43 | LRs: {0.06178612783488935}\n",
      "(trn) LOSS: 0.436668 | METRIC: 0.84782\n",
      "(val) LOSS: 0.996668 | METRIC: 0.8247\n",
      "EPOCH: 44 | LRs: {0.06023850647010523}\n",
      "(trn) LOSS: 0.428897 | METRIC: 0.85084\n",
      "(val) LOSS: 0.60301 | METRIC: 0.8411\n",
      "EPOCH: 45 | LRs: {0.058680575998569774}\n",
      "(trn) LOSS: 0.431427 | METRIC: 0.84848\n",
      "(val) LOSS: 1.372743 | METRIC: 0.8521\n",
      "EPOCH: 46 | LRs: {0.05711390512420774}\n",
      "(trn) LOSS: 0.421911 | METRIC: 0.85322\n",
      "(val) LOSS: 0.554325 | METRIC: 0.8254\n",
      "EPOCH: 47 | LRs: {0.05554007135178858}\n",
      "(trn) LOSS: 0.416396 | METRIC: 0.85636\n",
      "(val) LOSS: 0.519612 | METRIC: 0.8283\n",
      "EPOCH: 48 | LRs: {0.05396065939851297}\n",
      "(trn) LOSS: 0.413455 | METRIC: 0.8571\n",
      "(val) LOSS: 0.404519 | METRIC: 0.8356\n",
      "EPOCH: 49 | LRs: {0.05237725959833683}\n",
      "(trn) LOSS: 0.412456 | METRIC: 0.85616\n",
      "(val) LOSS: 0.261451 | METRIC: 0.8463\n",
      "EPOCH: 50 | LRs: {0.050791466300639854}\n",
      "(trn) LOSS: 0.405406 | METRIC: 0.85616\n",
      "(val) LOSS: 0.405041 | METRIC: 0.8583\n",
      "EPOCH: 51 | LRs: {0.04920487626485092}\n",
      "(trn) LOSS: 0.398201 | METRIC: 0.86124\n",
      "(val) LOSS: 0.775463 | METRIC: 0.8333\n",
      "EPOCH: 52 | LRs: {0.04761908705264657}\n",
      "(trn) LOSS: 0.396369 | METRIC: 0.8615\n",
      "(val) LOSS: 0.348388 | METRIC: 0.8554\n",
      "EPOCH: 53 | LRs: {0.04603569541934191}\n",
      "(trn) LOSS: 0.395751 | METRIC: 0.8631\n",
      "(val) LOSS: 0.152063 | METRIC: 0.8729\n",
      "EPOCH: 54 | LRs: {0.044456295706093295}\n",
      "(trn) LOSS: 0.385038 | METRIC: 0.86484\n",
      "(val) LOSS: 0.27478 | METRIC: 0.8725\n",
      "EPOCH: 55 | LRs: {0.042882478234532014}\n",
      "(trn) LOSS: 0.383451 | METRIC: 0.86608\n",
      "(val) LOSS: 0.581127 | METRIC: 0.8219\n",
      "EPOCH: 56 | LRs: {0.04131582770544513}\n",
      "(trn) LOSS: 0.379573 | METRIC: 0.86842\n",
      "(val) LOSS: 0.35289 | METRIC: 0.8658\n",
      "EPOCH: 57 | LRs: {0.03975792160311612}\n",
      "(trn) LOSS: 0.371428 | METRIC: 0.8709\n",
      "(val) LOSS: 0.174706 | METRIC: 0.8648\n",
      "EPOCH: 58 | LRs: {0.03821032860693203}\n",
      "(trn) LOSS: 0.36605 | METRIC: 0.87216\n",
      "(val) LOSS: 0.392231 | METRIC: 0.864\n",
      "EPOCH: 59 | LRs: {0.036674607011856146}\n",
      "(trn) LOSS: 0.362688 | METRIC: 0.87432\n",
      "(val) LOSS: 0.331688 | METRIC: 0.8516\n",
      "EPOCH: 60 | LRs: {0.035152303159357176}\n",
      "(trn) LOSS: 0.359968 | METRIC: 0.87542\n",
      "(val) LOSS: 0.326797 | METRIC: 0.8334\n",
      "EPOCH: 61 | LRs: {0.03364494988037439}\n",
      "(trn) LOSS: 0.349683 | METRIC: 0.87912\n",
      "(val) LOSS: 0.3787 | METRIC: 0.867\n",
      "EPOCH: 62 | LRs: {0.03215406495188691}\n",
      "(trn) LOSS: 0.345595 | METRIC: 0.8796\n",
      "(val) LOSS: 0.397165 | METRIC: 0.8663\n",
      "EPOCH: 63 | LRs: {0.0306811495686408}\n",
      "(trn) LOSS: 0.335677 | METRIC: 0.88306\n",
      "(val) LOSS: 0.592731 | METRIC: 0.8893\n",
      "EPOCH: 64 | LRs: {0.029227686831573247}\n",
      "(trn) LOSS: 0.335891 | METRIC: 0.88244\n",
      "(val) LOSS: 0.069397 | METRIC: 0.8631\n",
      "EPOCH: 65 | LRs: {0.02779514025445578}\n",
      "(trn) LOSS: 0.329758 | METRIC: 0.88462\n",
      "(val) LOSS: 0.79104 | METRIC: 0.8762\n",
      "EPOCH: 66 | LRs: {0.026384952290259743}\n",
      "(trn) LOSS: 0.328116 | METRIC: 0.88578\n",
      "(val) LOSS: 0.280096 | METRIC: 0.8828\n",
      "EPOCH: 67 | LRs: {0.02499854287872862}\n",
      "(trn) LOSS: 0.313979 | METRIC: 0.89062\n",
      "(val) LOSS: 0.471117 | METRIC: 0.8863\n",
      "EPOCH: 68 | LRs: {0.023637308016618872}\n",
      "(trn) LOSS: 0.306432 | METRIC: 0.89426\n",
      "(val) LOSS: 0.411288 | METRIC: 0.8853\n",
      "EPOCH: 69 | LRs: {0.02230261835204971}\n",
      "(trn) LOSS: 0.301412 | METRIC: 0.8949\n",
      "(val) LOSS: 0.10749 | METRIC: 0.8849\n",
      "EPOCH: 70 | LRs: {0.020995817804376586}\n",
      "(trn) LOSS: 0.285317 | METRIC: 0.9002\n",
      "(val) LOSS: 0.554095 | METRIC: 0.8892\n",
      "EPOCH: 71 | LRs: {0.01971822221097824}\n",
      "(trn) LOSS: 0.28762 | METRIC: 0.89892\n",
      "(val) LOSS: 0.605986 | METRIC: 0.8907\n",
      "EPOCH: 72 | LRs: {0.018471118002320114}\n",
      "(trn) LOSS: 0.275298 | METRIC: 0.90298\n",
      "(val) LOSS: 0.282105 | METRIC: 0.8974\n",
      "EPOCH: 73 | LRs: {0.01725576090662781}\n",
      "(trn) LOSS: 0.268376 | METRIC: 0.90678\n",
      "(val) LOSS: 0.144377 | METRIC: 0.8858\n",
      "EPOCH: 74 | LRs: {0.01607337468547529}\n",
      "(trn) LOSS: 0.258618 | METRIC: 0.91006\n",
      "(val) LOSS: 0.54334 | METRIC: 0.8967\n",
      "EPOCH: 75 | LRs: {0.014925149901560653}\n",
      "(trn) LOSS: 0.25135 | METRIC: 0.91204\n",
      "(val) LOSS: 0.09477 | METRIC: 0.8826\n",
      "EPOCH: 76 | LRs: {0.013812242719910448}\n",
      "(trn) LOSS: 0.238226 | METRIC: 0.916\n",
      "(val) LOSS: 0.060888 | METRIC: 0.8915\n",
      "EPOCH: 77 | LRs: {0.01273577374371952}\n",
      "(trn) LOSS: 0.232866 | METRIC: 0.91848\n",
      "(val) LOSS: 0.321109 | METRIC: 0.9055\n",
      "EPOCH: 78 | LRs: {0.0116968268859985}\n",
      "(trn) LOSS: 0.219822 | METRIC: 0.92216\n",
      "(val) LOSS: 0.177157 | METRIC: 0.9028\n",
      "EPOCH: 79 | LRs: {0.010696448278165389}\n",
      "(trn) LOSS: 0.20867 | METRIC: 0.92682\n",
      "(val) LOSS: 0.65801 | METRIC: 0.9112\n",
      "EPOCH: 80 | LRs: {0.00973564521667979}\n",
      "(trn) LOSS: 0.206323 | METRIC: 0.9278\n",
      "(val) LOSS: 0.141235 | METRIC: 0.8959\n",
      "EPOCH: 81 | LRs: {0.008815385148780837}\n",
      "(trn) LOSS: 0.194674 | METRIC: 0.93112\n",
      "(val) LOSS: 0.578191 | METRIC: 0.9108\n",
      "EPOCH: 82 | LRs: {0.007936594698349795}\n",
      "(trn) LOSS: 0.180526 | METRIC: 0.93688\n",
      "(val) LOSS: 0.340559 | METRIC: 0.9218\n",
      "EPOCH: 83 | LRs: {0.0071001587328783635}\n",
      "(trn) LOSS: 0.168034 | METRIC: 0.94066\n",
      "(val) LOSS: 0.10473 | METRIC: 0.9181\n",
      "EPOCH: 84 | LRs: {0.006306919472482149}\n",
      "(trn) LOSS: 0.158255 | METRIC: 0.94472\n",
      "(val) LOSS: 0.476017 | METRIC: 0.9178\n",
      "EPOCH: 85 | LRs: {0.00555767564185635}\n",
      "(trn) LOSS: 0.153979 | METRIC: 0.94604\n",
      "(val) LOSS: 0.009931 | METRIC: 0.9262\n",
      "EPOCH: 86 | LRs: {0.004853181666027719}\n",
      "(trn) LOSS: 0.140191 | METRIC: 0.95106\n",
      "(val) LOSS: 0.281983 | METRIC: 0.9229\n",
      "EPOCH: 87 | LRs: {0.004194146910712534}\n",
      "(trn) LOSS: 0.128686 | METRIC: 0.95444\n",
      "(val) LOSS: 0.053111 | METRIC: 0.9273\n",
      "EPOCH: 88 | LRs: {0.0035812349680454016}\n",
      "(trn) LOSS: 0.116566 | METRIC: 0.95898\n",
      "(val) LOSS: 0.365967 | METRIC: 0.9282\n",
      "EPOCH: 89 | LRs: {0.00301506298839827}\n",
      "(trn) LOSS: 0.109642 | METRIC: 0.96144\n",
      "(val) LOSS: 0.387788 | METRIC: 0.9276\n",
      "EPOCH: 90 | LRs: {0.0024962010589623007}\n",
      "(trn) LOSS: 0.102165 | METRIC: 0.96404\n",
      "(val) LOSS: 0.301855 | METRIC: 0.9288\n",
      "EPOCH: 91 | LRs: {0.0020251716297183904}\n",
      "(trn) LOSS: 0.096514 | METRIC: 0.96602\n",
      "(val) LOSS: 0.353985 | METRIC: 0.9305\n",
      "EPOCH: 92 | LRs: {0.0016024489873743427}\n",
      "(trn) LOSS: 0.086644 | METRIC: 0.9694\n",
      "(val) LOSS: 0.238243 | METRIC: 0.9336\n",
      "EPOCH: 93 | LRs: {0.0012284587777983227}\n",
      "(trn) LOSS: 0.081427 | METRIC: 0.97152\n",
      "(val) LOSS: 0.070761 | METRIC: 0.9381\n",
      "EPOCH: 94 | LRs: {0.0009035775774295846}\n",
      "(trn) LOSS: 0.076108 | METRIC: 0.97418\n",
      "(val) LOSS: 0.059961 | METRIC: 0.932\n",
      "EPOCH: 95 | LRs: {0.0006281325140978953}\n",
      "(trn) LOSS: 0.071134 | METRIC: 0.97562\n",
      "(val) LOSS: 0.009028 | METRIC: 0.9351\n",
      "EPOCH: 96 | LRs: {0.00040240093763356006}\n",
      "(trn) LOSS: 0.067852 | METRIC: 0.97772\n",
      "(val) LOSS: 0.063825 | METRIC: 0.9353\n",
      "EPOCH: 97 | LRs: {0.00022661014059962645}\n",
      "(trn) LOSS: 0.067964 | METRIC: 0.97702\n",
      "(val) LOSS: 0.005067 | METRIC: 0.9362\n",
      "EPOCH: 98 | LRs: {0.00010093712942756166}\n",
      "(trn) LOSS: 0.067081 | METRIC: 0.97764\n",
      "(val) LOSS: 0.066393 | METRIC: 0.9343\n",
      "EPOCH: 99 | LRs: {2.5508446186774587e-05}\n",
      "(trn) LOSS: 0.068317 | METRIC: 0.97664\n",
      "(val) LOSS: 0.080116 | METRIC: 0.9356\n",
      "Best Val Score: 0.9381\n",
      "Runtime: 2917\n"
     ]
    }
   ],
   "source": [
    "!python train.py --logdir resnet18 --patch_size 2 --epochs 100 --rel_pos 1 \\\n",
    "--rel_pos_mul 0 --n_out_convs 0 --squeeze_conv 1 --linformer 128 --conv_ratio 1.0 --n_mid_convs 10 \\\n",
    "--sep_conv 0 --dim 100 --mlp_dim 512 --depth 3 --heads 4 --cnn_baseline 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train Samples: 50000 | # Val Samples: 10000\n",
      "# Parameters: 11197009\n",
      "EPOCH: 0 | LRs: {0.0040000000000000036}\n",
      "/home/kimyoonsoo/projects/vit/model.py:19: UserWarning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629395347/work/aten/src/ATen/native/TensorIterator.cpp:918.)\n",
      "  return self.fn(x, **kwargs) + x\n",
      "(trn) LOSS: 1.805277 | METRIC: 0.33492\n",
      "(val) LOSS: 2.711078 | METRIC: 0.4597\n",
      "Runtime: 102\n",
      "EPOCH: 1 | LRs: {0.09999999995883255}\n",
      "(trn) LOSS: 1.534554 | METRIC: 0.4414\n",
      "(val) LOSS: 1.58948 | METRIC: 0.4846\n",
      "Runtime: 102\n",
      "EPOCH: 2 | LRs: {0.09997476280359487}\n",
      "(trn) LOSS: 1.386792 | METRIC: 0.50012\n",
      "(val) LOSS: 1.302097 | METRIC: 0.5838\n",
      "EPOCH: 3 | LRs: {0.09989920549977627}\n",
      "(trn) LOSS: 1.295435 | METRIC: 0.53454\n",
      "(val) LOSS: 1.731669 | METRIC: 0.5923\n",
      "EPOCH: 4 | LRs: {0.09977340412717695}\n",
      "(trn) LOSS: 1.224264 | METRIC: 0.56216\n",
      "(val) LOSS: 1.338418 | METRIC: 0.591\n",
      "EPOCH: 5 | LRs: {0.09959748535711543}\n",
      "(trn) LOSS: 1.158433 | METRIC: 0.58804\n",
      "(val) LOSS: 0.933888 | METRIC: 0.6301\n",
      "EPOCH: 6 | LRs: {0.09937162632488114}\n",
      "(trn) LOSS: 1.103194 | METRIC: 0.60938\n",
      "(val) LOSS: 1.070541 | METRIC: 0.7016\n",
      "EPOCH: 7 | LRs: {0.09909605445137433}\n",
      "(trn) LOSS: 1.049746 | METRIC: 0.63108\n",
      "(val) LOSS: 1.698612 | METRIC: 0.6724\n",
      "EPOCH: 8 | LRs: {0.09877104721411233}\n",
      "(trn) LOSS: 1.013632 | METRIC: 0.64624\n",
      "(val) LOSS: 1.642798 | METRIC: 0.6496\n",
      "EPOCH: 9 | LRs: {0.09839693186783342}\n",
      "(trn) LOSS: 0.98112 | METRIC: 0.65648\n",
      "(val) LOSS: 1.087849 | METRIC: 0.7298\n",
      "EPOCH: 10 | LRs: {0.0979740851149789}\n",
      "(trn) LOSS: 0.951858 | METRIC: 0.66638\n",
      "(val) LOSS: 0.838042 | METRIC: 0.7322\n",
      "EPOCH: 11 | LRs: {0.09750293272638572}\n",
      "(trn) LOSS: 0.915616 | METRIC: 0.6804\n",
      "(val) LOSS: 0.479488 | METRIC: 0.7545\n",
      "EPOCH: 12 | LRs: {0.09698394911257129}\n",
      "(trn) LOSS: 0.898257 | METRIC: 0.68514\n",
      "(val) LOSS: 0.955804 | METRIC: 0.741\n",
      "EPOCH: 13 | LRs: {0.09641765684604235}\n",
      "(trn) LOSS: 0.871129 | METRIC: 0.6964\n",
      "(val) LOSS: 0.56511 | METRIC: 0.7353\n",
      "EPOCH: 14 | LRs: {0.0958046261351088}\n",
      "(trn) LOSS: 0.862264 | METRIC: 0.69948\n",
      "(val) LOSS: 0.85663 | METRIC: 0.7425\n",
      "EPOCH: 15 | LRs: {0.09514547424973213}\n",
      "(trn) LOSS: 0.832788 | METRIC: 0.70908\n",
      "(val) LOSS: 0.949913 | METRIC: 0.7662\n",
      "EPOCH: 16 | LRs: {0.09444086489998703}\n",
      "(trn) LOSS: 0.821038 | METRIC: 0.71704\n",
      "(val) LOSS: 1.249443 | METRIC: 0.7207\n",
      "EPOCH: 17 | LRs: {0.0936915075677615}\n",
      "(trn) LOSS: 0.808289 | METRIC: 0.72046\n",
      "(val) LOSS: 0.556846 | METRIC: 0.7744\n",
      "EPOCH: 18 | LRs: {0.09289815679236878}\n",
      "(trn) LOSS: 0.787238 | METRIC: 0.72742\n",
      "(val) LOSS: 0.605633 | METRIC: 0.7186\n",
      "EPOCH: 19 | LRs: {0.09206161141079022}\n",
      "(trn) LOSS: 0.769512 | METRIC: 0.73476\n",
      "(val) LOSS: 0.952313 | METRIC: 0.7604\n",
      "EPOCH: 20 | LRs: {0.09118271375331419}\n",
      "(trn) LOSS: 0.763272 | METRIC: 0.73542\n",
      "(val) LOSS: 0.577081 | METRIC: 0.8026\n",
      "EPOCH: 21 | LRs: {0.09026234879538077}\n",
      "(trn) LOSS: 0.748576 | METRIC: 0.74266\n",
      "(val) LOSS: 0.678262 | METRIC: 0.8023\n",
      "EPOCH: 22 | LRs: {0.08930144326648662}\n",
      "(trn) LOSS: 0.740241 | METRIC: 0.74408\n",
      "(val) LOSS: 0.757328 | METRIC: 0.7843\n",
      "EPOCH: 23 | LRs: {0.08830096471704685}\n",
      "(trn) LOSS: 0.726521 | METRIC: 0.7499\n",
      "(val) LOSS: 0.649573 | METRIC: 0.8036\n",
      "EPOCH: 24 | LRs: {0.08726192054415381}\n",
      "(trn) LOSS: 0.72018 | METRIC: 0.75214\n",
      "(val) LOSS: 0.603331 | METRIC: 0.7783\n",
      "EPOCH: 25 | LRs: {0.08618535697721363}\n",
      "(trn) LOSS: 0.710791 | METRIC: 0.75426\n",
      "(val) LOSS: 0.511628 | METRIC: 0.7623\n",
      "EPOCH: 26 | LRs: {0.0850723580244818}\n",
      "(trn) LOSS: 0.700359 | METRIC: 0.7572\n",
      "(val) LOSS: 0.755138 | METRIC: 0.7766\n",
      "EPOCH: 27 | LRs: {0.08392404438155886}\n",
      "(trn) LOSS: 0.69507 | METRIC: 0.7605\n",
      "(val) LOSS: 0.691896 | METRIC: 0.7832\n",
      "EPOCH: 28 | LRs: {0.08274157230294484}\n",
      "(trn) LOSS: 0.679472 | METRIC: 0.76662\n",
      "(val) LOSS: 1.08745 | METRIC: 0.812\n",
      "EPOCH: 29 | LRs: {0.08152613243778901}\n",
      "(trn) LOSS: 0.673025 | METRIC: 0.76756\n",
      "(val) LOSS: 0.52131 | METRIC: 0.7978\n",
      "EPOCH: 30 | LRs: {0.08027894863100724}\n",
      "(trn) LOSS: 0.670366 | METRIC: 0.76716\n",
      "(val) LOSS: 0.253086 | METRIC: 0.809\n",
      "EPOCH: 31 | LRs: {0.07900127669097362}\n",
      "(trn) LOSS: 0.660693 | METRIC: 0.77012\n",
      "(val) LOSS: 0.365972 | METRIC: 0.8161\n",
      "EPOCH: 32 | LRs: {0.07769440312502822}\n",
      "(trn) LOSS: 0.645071 | METRIC: 0.7773\n",
      "(val) LOSS: 1.196149 | METRIC: 0.8104\n",
      "EPOCH: 33 | LRs: {0.07635964384407298}\n",
      "(trn) LOSS: 0.647031 | METRIC: 0.77606\n",
      "(val) LOSS: 1.158854 | METRIC: 0.8005\n",
      "EPOCH: 34 | LRs: {0.07499834283756114}\n",
      "(trn) LOSS: 0.639513 | METRIC: 0.77812\n",
      "(val) LOSS: 0.558195 | METRIC: 0.8309\n",
      "EPOCH: 35 | LRs: {0.07361187082021371}\n",
      "(trn) LOSS: 0.628792 | METRIC: 0.7816\n",
      "(val) LOSS: 0.800306 | METRIC: 0.8229\n",
      "EPOCH: 36 | LRs: {0.07220162385182598}\n",
      "(trn) LOSS: 0.625375 | METRIC: 0.78368\n",
      "(val) LOSS: 1.151302 | METRIC: 0.799\n",
      "EPOCH: 37 | LRs: {0.07076902193155353}\n",
      "(trn) LOSS: 0.613076 | METRIC: 0.78716\n",
      "(val) LOSS: 0.637872 | METRIC: 0.8267\n",
      "EPOCH: 38 | LRs: {0.06931550756809367}\n",
      "(trn) LOSS: 0.609659 | METRIC: 0.792\n",
      "(val) LOSS: 0.781685 | METRIC: 0.8196\n",
      "EPOCH: 39 | LRs: {0.06784254432720126}\n",
      "(trn) LOSS: 0.606235 | METRIC: 0.7931\n",
      "(val) LOSS: 0.68418 | METRIC: 0.8474\n",
      "EPOCH: 40 | LRs: {0.06635161535800212}\n",
      "(trn) LOSS: 0.597298 | METRIC: 0.79312\n",
      "(val) LOSS: 0.465137 | METRIC: 0.8461\n",
      "EPOCH: 41 | LRs: {0.0648442218995876}\n",
      "(trn) LOSS: 0.589357 | METRIC: 0.79808\n",
      "(val) LOSS: 0.6379 | METRIC: 0.8369\n",
      "EPOCH: 42 | LRs: {0.06332188176939406}\n",
      "(trn) LOSS: 0.586543 | METRIC: 0.79776\n",
      "(val) LOSS: 0.644929 | METRIC: 0.8436\n",
      "EPOCH: 43 | LRs: {0.06178612783488935}\n",
      "(trn) LOSS: 0.578508 | METRIC: 0.80216\n",
      "(val) LOSS: 0.627929 | METRIC: 0.8212\n",
      "EPOCH: 44 | LRs: {0.06023850647010523}\n",
      "(trn) LOSS: 0.572429 | METRIC: 0.804\n",
      "(val) LOSS: 1.029301 | METRIC: 0.8361\n",
      "EPOCH: 45 | LRs: {0.058680575998569774}\n",
      "(trn) LOSS: 0.56434 | METRIC: 0.805\n",
      "(val) LOSS: 0.804164 | METRIC: 0.8491\n",
      "EPOCH: 46 | LRs: {0.05711390512420774}\n",
      "(trn) LOSS: 0.559362 | METRIC: 0.80684\n",
      "(val) LOSS: 0.649392 | METRIC: 0.8334\n",
      "EPOCH: 47 | LRs: {0.05554007135178858}\n",
      "(trn) LOSS: 0.558706 | METRIC: 0.80538\n",
      "(val) LOSS: 0.361434 | METRIC: 0.8584\n",
      "EPOCH: 48 | LRs: {0.05396065939851297}\n",
      "(trn) LOSS: 0.546587 | METRIC: 0.81044\n",
      "(val) LOSS: 0.829908 | METRIC: 0.8309\n",
      "EPOCH: 49 | LRs: {0.05237725959833683}\n",
      "(trn) LOSS: 0.541578 | METRIC: 0.81158\n",
      "(val) LOSS: 0.39397 | METRIC: 0.8656\n",
      "EPOCH: 50 | LRs: {0.050791466300639854}\n",
      "(trn) LOSS: 0.534727 | METRIC: 0.81448\n",
      "(val) LOSS: 0.475079 | METRIC: 0.8513\n",
      "EPOCH: 51 | LRs: {0.04920487626485092}\n",
      "(trn) LOSS: 0.524077 | METRIC: 0.81948\n",
      "(val) LOSS: 0.343515 | METRIC: 0.8342\n",
      "EPOCH: 52 | LRs: {0.04761908705264657}\n",
      "(trn) LOSS: 0.523335 | METRIC: 0.81678\n",
      "(val) LOSS: 0.403884 | METRIC: 0.8642\n",
      "EPOCH: 53 | LRs: {0.04603569541934191}\n",
      "(trn) LOSS: 0.509645 | METRIC: 0.82298\n",
      "(val) LOSS: 0.546854 | METRIC: 0.8314\n",
      "EPOCH: 54 | LRs: {0.044456295706093295}\n",
      "(trn) LOSS: 0.506513 | METRIC: 0.82402\n",
      "(val) LOSS: 0.367285 | METRIC: 0.8575\n",
      "EPOCH: 55 | LRs: {0.042882478234532014}\n",
      "(trn) LOSS: 0.498529 | METRIC: 0.82798\n",
      "(val) LOSS: 0.614711 | METRIC: 0.8599\n",
      "EPOCH: 56 | LRs: {0.04131582770544513}\n",
      "(trn) LOSS: 0.49286 | METRIC: 0.82994\n",
      "(val) LOSS: 0.388893 | METRIC: 0.8578\n",
      "EPOCH: 57 | LRs: {0.03975792160311612}\n",
      "(trn) LOSS: 0.477497 | METRIC: 0.83398\n",
      "(val) LOSS: 0.141082 | METRIC: 0.864\n",
      "EPOCH: 58 | LRs: {0.03821032860693203}\n",
      "(trn) LOSS: 0.475614 | METRIC: 0.83478\n",
      "(val) LOSS: 0.542168 | METRIC: 0.8697\n",
      "EPOCH: 59 | LRs: {0.036674607011856146}\n",
      "(trn) LOSS: 0.468459 | METRIC: 0.83928\n",
      "(val) LOSS: 0.384779 | METRIC: 0.8628\n",
      "EPOCH: 60 | LRs: {0.035152303159357176}\n",
      "(trn) LOSS: 0.453555 | METRIC: 0.84284\n",
      "(val) LOSS: 0.507164 | METRIC: 0.8821\n",
      "EPOCH: 61 | LRs: {0.03364494988037439}\n",
      "(trn) LOSS: 0.457875 | METRIC: 0.84184\n",
      "(val) LOSS: 0.549389 | METRIC: 0.8684\n",
      "EPOCH: 62 | LRs: {0.03215406495188691}\n",
      "(trn) LOSS: 0.445054 | METRIC: 0.84392\n",
      "(val) LOSS: 0.602133 | METRIC: 0.8658\n",
      "EPOCH: 63 | LRs: {0.0306811495686408}\n",
      "(trn) LOSS: 0.436682 | METRIC: 0.84772\n",
      "(val) LOSS: 0.725014 | METRIC: 0.8786\n",
      "EPOCH: 64 | LRs: {0.029227686831573247}\n",
      "(trn) LOSS: 0.425583 | METRIC: 0.8522\n",
      "(val) LOSS: 0.393893 | METRIC: 0.8731\n",
      "EPOCH: 65 | LRs: {0.02779514025445578}\n",
      "(trn) LOSS: 0.427601 | METRIC: 0.85082\n",
      "(val) LOSS: 0.459086 | METRIC: 0.8667\n",
      "EPOCH: 66 | LRs: {0.026384952290259743}\n",
      "(trn) LOSS: 0.411129 | METRIC: 0.85762\n",
      "(val) LOSS: 0.763871 | METRIC: 0.8741\n",
      "EPOCH: 67 | LRs: {0.02499854287872862}\n",
      "(trn) LOSS: 0.399668 | METRIC: 0.86008\n",
      "(val) LOSS: 0.190138 | METRIC: 0.8797\n",
      "EPOCH: 68 | LRs: {0.023637308016618872}\n",
      "(trn) LOSS: 0.391358 | METRIC: 0.86262\n",
      "(val) LOSS: 0.2603 | METRIC: 0.8931\n",
      "EPOCH: 69 | LRs: {0.02230261835204971}\n",
      "(trn) LOSS: 0.381305 | METRIC: 0.86588\n",
      "(val) LOSS: 0.207043 | METRIC: 0.8848\n",
      "EPOCH: 70 | LRs: {0.020995817804376586}\n",
      "(trn) LOSS: 0.375993 | METRIC: 0.86932\n",
      "(val) LOSS: 0.284493 | METRIC: 0.8873\n",
      "EPOCH: 71 | LRs: {0.01971822221097824}\n",
      "(trn) LOSS: 0.358726 | METRIC: 0.87584\n",
      "(val) LOSS: 0.210967 | METRIC: 0.8714\n",
      "EPOCH: 72 | LRs: {0.018471118002320114}\n",
      "(trn) LOSS: 0.350967 | METRIC: 0.87666\n",
      "(val) LOSS: 0.466832 | METRIC: 0.8794\n",
      "EPOCH: 73 | LRs: {0.01725576090662781}\n",
      "(trn) LOSS: 0.340942 | METRIC: 0.88054\n",
      "(val) LOSS: 0.268437 | METRIC: 0.8786\n",
      "EPOCH: 74 | LRs: {0.01607337468547529}\n",
      "(trn) LOSS: 0.32845 | METRIC: 0.88494\n",
      "(val) LOSS: 0.528095 | METRIC: 0.8932\n",
      "EPOCH: 75 | LRs: {0.014925149901560653}\n",
      "(trn) LOSS: 0.317397 | METRIC: 0.88902\n",
      "(val) LOSS: 0.331478 | METRIC: 0.8886\n",
      "EPOCH: 76 | LRs: {0.013812242719910448}\n",
      "(trn) LOSS: 0.306685 | METRIC: 0.894\n",
      "(val) LOSS: 0.601004 | METRIC: 0.8971\n",
      "EPOCH: 77 | LRs: {0.01273577374371952}\n",
      "(trn) LOSS: 0.291754 | METRIC: 0.89814\n",
      "(val) LOSS: 0.030295 | METRIC: 0.9004\n",
      "EPOCH: 78 | LRs: {0.0116968268859985}\n",
      "(trn) LOSS: 0.277647 | METRIC: 0.90212\n",
      "(val) LOSS: 0.151652 | METRIC: 0.902\n",
      "EPOCH: 79 | LRs: {0.010696448278165389}\n",
      "(trn) LOSS: 0.26543 | METRIC: 0.9062\n",
      "(val) LOSS: 0.137857 | METRIC: 0.8966\n",
      "EPOCH: 80 | LRs: {0.00973564521667979}\n",
      "(trn) LOSS: 0.257228 | METRIC: 0.91092\n",
      "(val) LOSS: 0.29819 | METRIC: 0.9104\n",
      "EPOCH: 81 | LRs: {0.008815385148780837}\n",
      "(trn) LOSS: 0.244879 | METRIC: 0.91296\n",
      "(val) LOSS: 0.062715 | METRIC: 0.9091\n",
      "EPOCH: 82 | LRs: {0.007936594698349795}\n",
      "(trn) LOSS: 0.230346 | METRIC: 0.91876\n",
      "(val) LOSS: 0.552792 | METRIC: 0.9124\n",
      "EPOCH: 83 | LRs: {0.0071001587328783635}\n",
      "(trn) LOSS: 0.216957 | METRIC: 0.9236\n",
      "(val) LOSS: 0.494383 | METRIC: 0.9168\n",
      "EPOCH: 84 | LRs: {0.006306919472482149}\n",
      "(trn) LOSS: 0.199914 | METRIC: 0.93026\n",
      "(val) LOSS: 0.095921 | METRIC: 0.9175\n",
      "EPOCH: 85 | LRs: {0.00555767564185635}\n",
      "(trn) LOSS: 0.189589 | METRIC: 0.93282\n",
      "(val) LOSS: 0.470527 | METRIC: 0.9171\n",
      "EPOCH: 86 | LRs: {0.004853181666027719}\n",
      "(trn) LOSS: 0.177084 | METRIC: 0.93672\n",
      "(val) LOSS: 0.144649 | METRIC: 0.9174\n",
      "EPOCH: 87 | LRs: {0.004194146910712534}\n",
      "(trn) LOSS: 0.169702 | METRIC: 0.94004\n",
      "(val) LOSS: 0.060914 | METRIC: 0.918\n",
      "EPOCH: 88 | LRs: {0.0035812349680454016}\n",
      "(trn) LOSS: 0.154607 | METRIC: 0.9452\n",
      "(val) LOSS: 0.094436 | METRIC: 0.9219\n",
      "EPOCH: 89 | LRs: {0.00301506298839827}\n",
      "(trn) LOSS: 0.146675 | METRIC: 0.94758\n",
      "(val) LOSS: 0.007524 | METRIC: 0.9204\n",
      "EPOCH: 90 | LRs: {0.0024962010589623007}\n",
      "(trn) LOSS: 0.135295 | METRIC: 0.95244\n",
      "(val) LOSS: 0.088659 | METRIC: 0.9261\n",
      "EPOCH: 91 | LRs: {0.0020251716297183904}\n",
      "(trn) LOSS: 0.125681 | METRIC: 0.95628\n",
      "(val) LOSS: 0.295105 | METRIC: 0.9258\n",
      "EPOCH: 92 | LRs: {0.0016024489873743427}\n",
      "(trn) LOSS: 0.119926 | METRIC: 0.95846\n",
      "(val) LOSS: 0.012199 | METRIC: 0.9259\n",
      "EPOCH: 93 | LRs: {0.0012284587777983227}\n",
      "(trn) LOSS: 0.109996 | METRIC: 0.9612\n",
      "(val) LOSS: 0.123681 | METRIC: 0.9264\n",
      "EPOCH: 94 | LRs: {0.0009035775774295846}\n",
      "(trn) LOSS: 0.11068 | METRIC: 0.96118\n",
      "(val) LOSS: 0.142975 | METRIC: 0.928\n",
      "EPOCH: 95 | LRs: {0.0006281325140978953}\n",
      "(trn) LOSS: 0.101682 | METRIC: 0.96408\n",
      "(val) LOSS: 0.229572 | METRIC: 0.9313\n",
      "EPOCH: 96 | LRs: {0.00040240093763356006}\n",
      "(trn) LOSS: 0.101903 | METRIC: 0.96464\n",
      "(val) LOSS: 0.088445 | METRIC: 0.929\n",
      "EPOCH: 97 | LRs: {0.00022661014059962645}\n",
      "(trn) LOSS: 0.100551 | METRIC: 0.96542\n",
      "(val) LOSS: 0.005093 | METRIC: 0.9297\n",
      "EPOCH: 98 | LRs: {0.00010093712942756166}\n",
      "(trn) LOSS: 0.095941 | METRIC: 0.9661\n",
      "(val) LOSS: 0.440812 | METRIC: 0.929\n",
      "EPOCH: 99 | LRs: {2.5508446186774587e-05}\n",
      "(trn) LOSS: 0.10021 | METRIC: 0.9654\n",
      "(val) LOSS: 0.162404 | METRIC: 0.9295\n",
      "Best Val Score: 0.9313\n",
      "Runtime: 10392\n"
     ]
    }
   ],
   "source": [
    "!python train.py --logdir convratio1.0 --patch_size 2 --epochs 100 --rel_pos 1 \\\n",
    "--rel_pos_mul 0 --n_out_convs 0 --squeeze_conv 1 --linformer 0 --conv_ratio 1.0 --n_mid_convs 6 \\\n",
    "--sep_conv 0 --dim 251 --mlp_dim 512 --depth 3 --heads 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train Samples: 50000 | # Val Samples: 10000\n",
      "# Parameters: 10770094\n",
      "EPOCH: 0 | LRs: {0.0040000000000000036}\n",
      "/home/kimyoonsoo/projects/vit/model.py:19: UserWarning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629395347/work/aten/src/ATen/native/TensorIterator.cpp:918.)\n",
      "  return self.fn(x, **kwargs) + x\n",
      "[W TensorIterator.cpp:924] Warning: Mixed memory format inputs detected while calling the operator. The operator will output channels_last tensor even if some of the inputs are not in channels_last format. (function operator())\n",
      "(trn) LOSS: 1.823978 | METRIC: 0.32734\n",
      "(val) LOSS: 2.001468 | METRIC: 0.4106\n",
      "Runtime: 143\n",
      "EPOCH: 1 | LRs: {0.09999999995883255}\n",
      "(trn) LOSS: 1.580068 | METRIC: 0.42184\n",
      "(val) LOSS: 1.654785 | METRIC: 0.5092\n",
      "Runtime: 144\n",
      "EPOCH: 2 | LRs: {0.09997476280359487}\n",
      "(trn) LOSS: 1.445361 | METRIC: 0.47526\n",
      "(val) LOSS: 1.658636 | METRIC: 0.5351\n",
      "EPOCH: 3 | LRs: {0.09989920549977627}\n",
      "(trn) LOSS: 1.353437 | METRIC: 0.5101\n",
      "(val) LOSS: 1.105488 | METRIC: 0.5994\n",
      "EPOCH: 4 | LRs: {0.09977340412717695}\n",
      "(trn) LOSS: 1.283042 | METRIC: 0.5379\n",
      "(val) LOSS: 1.105544 | METRIC: 0.6204\n",
      "EPOCH: 5 | LRs: {0.09959748535711543}\n",
      "(trn) LOSS: 1.21254 | METRIC: 0.56608\n",
      "(val) LOSS: 1.020842 | METRIC: 0.6613\n",
      "EPOCH: 6 | LRs: {0.09937162632488114}\n",
      "(trn) LOSS: 1.162217 | METRIC: 0.58622\n",
      "(val) LOSS: 1.463542 | METRIC: 0.6721\n",
      "EPOCH: 7 | LRs: {0.09909605445137433}\n",
      "(trn) LOSS: 1.111534 | METRIC: 0.60328\n",
      "(val) LOSS: 0.829213 | METRIC: 0.6576\n",
      "EPOCH: 8 | LRs: {0.09877104721411233}\n",
      "(trn) LOSS: 1.070036 | METRIC: 0.62134\n",
      "(val) LOSS: 0.927185 | METRIC: 0.6579\n",
      "EPOCH: 9 | LRs: {0.09839693186783342}\n",
      "(trn) LOSS: 1.036171 | METRIC: 0.63536\n",
      "(val) LOSS: 1.304258 | METRIC: 0.6721\n",
      "EPOCH: 10 | LRs: {0.0979740851149789}\n",
      "(trn) LOSS: 1.010962 | METRIC: 0.64676\n",
      "(val) LOSS: 0.920883 | METRIC: 0.7056\n",
      "EPOCH: 11 | LRs: {0.09750293272638572}\n",
      "(trn) LOSS: 0.980721 | METRIC: 0.65798\n",
      "(val) LOSS: 0.779369 | METRIC: 0.7487\n",
      "EPOCH: 12 | LRs: {0.09698394911257129}\n",
      "(trn) LOSS: 0.950516 | METRIC: 0.66862\n",
      "(val) LOSS: 0.541028 | METRIC: 0.6421\n",
      "EPOCH: 13 | LRs: {0.09641765684604235}\n",
      "(trn) LOSS: 0.937099 | METRIC: 0.6714\n",
      "(val) LOSS: 0.420708 | METRIC: 0.7405\n",
      "EPOCH: 14 | LRs: {0.0958046261351088}\n",
      "(trn) LOSS: 0.906642 | METRIC: 0.68392\n",
      "(val) LOSS: 0.66657 | METRIC: 0.6942\n",
      "EPOCH: 15 | LRs: {0.09514547424973213}\n",
      "(trn) LOSS: 0.887923 | METRIC: 0.69236\n",
      "(val) LOSS: 0.982742 | METRIC: 0.7301\n",
      "EPOCH: 16 | LRs: {0.09444086489998703}\n",
      "(trn) LOSS: 0.865922 | METRIC: 0.70046\n",
      "(val) LOSS: 1.057847 | METRIC: 0.7249\n",
      "EPOCH: 17 | LRs: {0.0936915075677615}\n",
      "(trn) LOSS: 0.84319 | METRIC: 0.71072\n",
      "(val) LOSS: 0.60957 | METRIC: 0.7056\n",
      "EPOCH: 18 | LRs: {0.09289815679236878}\n",
      "(trn) LOSS: 0.832022 | METRIC: 0.7109\n",
      "(val) LOSS: 0.946003 | METRIC: 0.7771\n",
      "EPOCH: 19 | LRs: {0.09206161141079022}\n",
      "(trn) LOSS: 0.815366 | METRIC: 0.72018\n",
      "(val) LOSS: 0.712622 | METRIC: 0.7603\n",
      "EPOCH: 20 | LRs: {0.09118271375331419}\n",
      "(trn) LOSS: 0.801743 | METRIC: 0.72188\n",
      "(val) LOSS: 0.809911 | METRIC: 0.7693\n",
      "EPOCH: 21 | LRs: {0.09026234879538077}\n",
      "(trn) LOSS: 0.790323 | METRIC: 0.72658\n",
      "(val) LOSS: 1.517403 | METRIC: 0.7795\n",
      "EPOCH: 22 | LRs: {0.08930144326648662}\n",
      "(trn) LOSS: 0.766946 | METRIC: 0.73364\n",
      "(val) LOSS: 0.700177 | METRIC: 0.8036\n",
      "EPOCH: 23 | LRs: {0.08830096471704685}\n",
      "(trn) LOSS: 0.74797 | METRIC: 0.74092\n",
      "(val) LOSS: 0.445194 | METRIC: 0.7695\n",
      "EPOCH: 24 | LRs: {0.08726192054415381}\n",
      "(trn) LOSS: 0.74971 | METRIC: 0.7424\n",
      "(val) LOSS: 0.355652 | METRIC: 0.7655\n",
      "EPOCH: 25 | LRs: {0.08618535697721363}\n",
      "(trn) LOSS: 0.728383 | METRIC: 0.75012\n",
      "(val) LOSS: 1.134154 | METRIC: 0.7931\n",
      "EPOCH: 26 | LRs: {0.0850723580244818}\n",
      "(trn) LOSS: 0.721009 | METRIC: 0.75182\n",
      "(val) LOSS: 0.601415 | METRIC: 0.7969\n",
      "EPOCH: 27 | LRs: {0.08392404438155886}\n",
      "(trn) LOSS: 0.711733 | METRIC: 0.75658\n",
      "(val) LOSS: 0.432678 | METRIC: 0.8064\n",
      "EPOCH: 28 | LRs: {0.08274157230294484}\n",
      "(trn) LOSS: 0.700497 | METRIC: 0.75968\n",
      "(val) LOSS: 0.752693 | METRIC: 0.7974\n",
      "EPOCH: 29 | LRs: {0.08152613243778901}\n",
      "(trn) LOSS: 0.692098 | METRIC: 0.76116\n",
      "(val) LOSS: 0.772796 | METRIC: 0.7985\n",
      "EPOCH: 30 | LRs: {0.08027894863100724}\n",
      "(trn) LOSS: 0.682631 | METRIC: 0.76442\n",
      "(val) LOSS: 1.068913 | METRIC: 0.7969\n",
      "EPOCH: 31 | LRs: {0.07900127669097362}\n",
      "(trn) LOSS: 0.682125 | METRIC: 0.76374\n",
      "(val) LOSS: 1.065997 | METRIC: 0.7553\n",
      "EPOCH: 32 | LRs: {0.07769440312502822}\n",
      "(trn) LOSS: 0.663236 | METRIC: 0.7711\n",
      "(val) LOSS: 1.031985 | METRIC: 0.826\n",
      "EPOCH: 33 | LRs: {0.07635964384407298}\n",
      "(trn) LOSS: 0.659115 | METRIC: 0.77328\n",
      "(val) LOSS: 0.431346 | METRIC: 0.8406\n",
      "EPOCH: 34 | LRs: {0.07499834283756114}\n",
      "(trn) LOSS: 0.650401 | METRIC: 0.77572\n",
      "(val) LOSS: 0.481008 | METRIC: 0.8262\n",
      "EPOCH: 35 | LRs: {0.07361187082021371}\n",
      "(trn) LOSS: 0.645643 | METRIC: 0.7774\n",
      "(val) LOSS: 0.342651 | METRIC: 0.8254\n",
      "EPOCH: 36 | LRs: {0.07220162385182598}\n",
      "(trn) LOSS: 0.638918 | METRIC: 0.78126\n",
      "(val) LOSS: 1.163693 | METRIC: 0.8006\n",
      "EPOCH: 37 | LRs: {0.07076902193155353}\n",
      "(trn) LOSS: 0.631451 | METRIC: 0.78142\n",
      "(val) LOSS: 0.376355 | METRIC: 0.8253\n",
      "EPOCH: 38 | LRs: {0.06931550756809367}\n",
      "(trn) LOSS: 0.630082 | METRIC: 0.78184\n",
      "(val) LOSS: 0.537905 | METRIC: 0.8247\n",
      "EPOCH: 39 | LRs: {0.06784254432720126}\n",
      "(trn) LOSS: 0.613606 | METRIC: 0.78834\n",
      "(val) LOSS: 0.961649 | METRIC: 0.8174\n",
      "EPOCH: 40 | LRs: {0.06635161535800212}\n",
      "(trn) LOSS: 0.607977 | METRIC: 0.7906\n",
      "(val) LOSS: 0.093173 | METRIC: 0.7998\n",
      "EPOCH: 41 | LRs: {0.0648442218995876}\n",
      "(trn) LOSS: 0.596054 | METRIC: 0.79586\n",
      "(val) LOSS: 0.925342 | METRIC: 0.8246\n",
      "EPOCH: 42 | LRs: {0.06332188176939406}\n",
      "(trn) LOSS: 0.601247 | METRIC: 0.79338\n",
      "(val) LOSS: 0.397347 | METRIC: 0.8334\n",
      "EPOCH: 43 | LRs: {0.06178612783488935}\n",
      "(trn) LOSS: 0.587508 | METRIC: 0.7979\n",
      "(val) LOSS: 0.655155 | METRIC: 0.8138\n",
      "EPOCH: 44 | LRs: {0.06023850647010523}\n",
      "(trn) LOSS: 0.579158 | METRIC: 0.80028\n",
      "(val) LOSS: 1.02971 | METRIC: 0.8384\n",
      "EPOCH: 45 | LRs: {0.058680575998569774}\n",
      "(trn) LOSS: 0.57786 | METRIC: 0.80096\n",
      "(val) LOSS: 0.719477 | METRIC: 0.8204\n",
      "EPOCH: 46 | LRs: {0.05711390512420774}\n",
      "(trn) LOSS: 0.568705 | METRIC: 0.80364\n",
      "(val) LOSS: 0.315489 | METRIC: 0.8426\n",
      "EPOCH: 47 | LRs: {0.05554007135178858}\n",
      "(trn) LOSS: 0.560301 | METRIC: 0.8045\n",
      "(val) LOSS: 0.670085 | METRIC: 0.8333\n",
      "EPOCH: 48 | LRs: {0.05396065939851297}\n",
      "(trn) LOSS: 0.558184 | METRIC: 0.80808\n",
      "(val) LOSS: 0.891624 | METRIC: 0.8485\n",
      "EPOCH: 49 | LRs: {0.05237725959833683}\n",
      "(trn) LOSS: 0.551009 | METRIC: 0.8097\n",
      "(val) LOSS: 0.416736 | METRIC: 0.8346\n",
      "EPOCH: 50 | LRs: {0.050791466300639854}\n",
      "(trn) LOSS: 0.545458 | METRIC: 0.81224\n",
      "(val) LOSS: 0.248656 | METRIC: 0.8295\n",
      "EPOCH: 51 | LRs: {0.04920487626485092}\n",
      "(trn) LOSS: 0.529326 | METRIC: 0.81722\n",
      "(val) LOSS: 1.117208 | METRIC: 0.8454\n",
      "EPOCH: 52 | LRs: {0.04761908705264657}\n",
      "(trn) LOSS: 0.527659 | METRIC: 0.82082\n",
      "(val) LOSS: 0.935417 | METRIC: 0.8491\n",
      "EPOCH: 53 | LRs: {0.04603569541934191}\n",
      "(trn) LOSS: 0.523813 | METRIC: 0.81934\n",
      "(val) LOSS: 0.497921 | METRIC: 0.8524\n",
      "EPOCH: 54 | LRs: {0.044456295706093295}\n",
      "(trn) LOSS: 0.512779 | METRIC: 0.8216\n",
      "(val) LOSS: 0.45362 | METRIC: 0.8322\n",
      "EPOCH: 55 | LRs: {0.042882478234532014}\n",
      "(trn) LOSS: 0.508572 | METRIC: 0.82586\n",
      "(val) LOSS: 0.917736 | METRIC: 0.8604\n",
      "EPOCH: 56 | LRs: {0.04131582770544513}\n",
      "(trn) LOSS: 0.496053 | METRIC: 0.829\n",
      "(val) LOSS: 0.2958 | METRIC: 0.8449\n",
      "EPOCH: 57 | LRs: {0.03975792160311612}\n",
      "(trn) LOSS: 0.489026 | METRIC: 0.83062\n",
      "(val) LOSS: 0.349941 | METRIC: 0.8488\n",
      "EPOCH: 58 | LRs: {0.03821032860693203}\n",
      "(trn) LOSS: 0.481461 | METRIC: 0.83404\n",
      "(val) LOSS: 0.093764 | METRIC: 0.8742\n",
      "EPOCH: 59 | LRs: {0.036674607011856146}\n",
      "(trn) LOSS: 0.471278 | METRIC: 0.83894\n",
      "(val) LOSS: 0.263783 | METRIC: 0.8638\n",
      "EPOCH: 60 | LRs: {0.035152303159357176}\n",
      "(trn) LOSS: 0.466584 | METRIC: 0.83844\n",
      "(val) LOSS: 0.413689 | METRIC: 0.873\n",
      "EPOCH: 61 | LRs: {0.03364494988037439}\n",
      "(trn) LOSS: 0.458754 | METRIC: 0.841\n",
      "(val) LOSS: 0.578762 | METRIC: 0.8512\n",
      "EPOCH: 62 | LRs: {0.03215406495188691}\n",
      "(trn) LOSS: 0.446112 | METRIC: 0.84576\n",
      "(val) LOSS: 1.010253 | METRIC: 0.8695\n",
      "EPOCH: 63 | LRs: {0.0306811495686408}\n",
      "(trn) LOSS: 0.441541 | METRIC: 0.847\n",
      "(val) LOSS: 0.464368 | METRIC: 0.8741\n",
      "EPOCH: 64 | LRs: {0.029227686831573247}\n",
      "(trn) LOSS: 0.434643 | METRIC: 0.8477\n",
      "(val) LOSS: 0.125261 | METRIC: 0.8678\n",
      "EPOCH: 65 | LRs: {0.02779514025445578}\n",
      "(trn) LOSS: 0.423229 | METRIC: 0.8547\n",
      "(val) LOSS: 0.385216 | METRIC: 0.8668\n",
      "EPOCH: 66 | LRs: {0.026384952290259743}\n",
      "(trn) LOSS: 0.413919 | METRIC: 0.85626\n",
      "(val) LOSS: 0.231333 | METRIC: 0.8783\n",
      "EPOCH: 67 | LRs: {0.02499854287872862}\n",
      "(trn) LOSS: 0.40585 | METRIC: 0.85832\n",
      "(val) LOSS: 0.347674 | METRIC: 0.8786\n",
      "EPOCH: 68 | LRs: {0.023637308016618872}\n",
      "(trn) LOSS: 0.39709 | METRIC: 0.86348\n",
      "(val) LOSS: 0.369238 | METRIC: 0.875\n",
      "EPOCH: 69 | LRs: {0.02230261835204971}\n",
      "(trn) LOSS: 0.390574 | METRIC: 0.86508\n",
      "(val) LOSS: 0.220057 | METRIC: 0.8975\n",
      "EPOCH: 70 | LRs: {0.020995817804376586}\n",
      "(trn) LOSS: 0.373268 | METRIC: 0.87168\n",
      "(val) LOSS: 0.613681 | METRIC: 0.8872\n",
      "EPOCH: 71 | LRs: {0.01971822221097824}\n",
      "(trn) LOSS: 0.365852 | METRIC: 0.87406\n",
      "(val) LOSS: 0.210316 | METRIC: 0.8913\n",
      "EPOCH: 72 | LRs: {0.018471118002320114}\n",
      "(trn) LOSS: 0.359101 | METRIC: 0.87394\n",
      "(val) LOSS: 0.422317 | METRIC: 0.8981\n",
      "EPOCH: 73 | LRs: {0.01725576090662781}\n",
      "(trn) LOSS: 0.344383 | METRIC: 0.87984\n",
      "(val) LOSS: 0.899111 | METRIC: 0.8867\n",
      "EPOCH: 74 | LRs: {0.01607337468547529}\n",
      "(trn) LOSS: 0.330607 | METRIC: 0.8849\n",
      "(val) LOSS: 0.386069 | METRIC: 0.8915\n",
      "EPOCH: 75 | LRs: {0.014925149901560653}\n",
      "(trn) LOSS: 0.322251 | METRIC: 0.88722\n",
      "(val) LOSS: 0.288468 | METRIC: 0.8979\n",
      "EPOCH: 76 | LRs: {0.013812242719910448}\n",
      "(trn) LOSS: 0.301576 | METRIC: 0.8947\n",
      "(val) LOSS: 0.482661 | METRIC: 0.9028\n",
      "EPOCH: 77 | LRs: {0.01273577374371952}\n",
      "(trn) LOSS: 0.293958 | METRIC: 0.89772\n",
      "(val) LOSS: 0.271835 | METRIC: 0.9015\n",
      "EPOCH: 78 | LRs: {0.0116968268859985}\n",
      "(trn) LOSS: 0.284774 | METRIC: 0.90082\n",
      "(val) LOSS: 0.209501 | METRIC: 0.8964\n",
      "EPOCH: 79 | LRs: {0.010696448278165389}\n",
      "(trn) LOSS: 0.26905 | METRIC: 0.90558\n",
      "(val) LOSS: 0.061391 | METRIC: 0.9106\n",
      "EPOCH: 80 | LRs: {0.00973564521667979}\n",
      "(trn) LOSS: 0.260891 | METRIC: 0.90892\n",
      "(val) LOSS: 0.162304 | METRIC: 0.8972\n",
      "EPOCH: 81 | LRs: {0.008815385148780837}\n",
      "(trn) LOSS: 0.244985 | METRIC: 0.91418\n",
      "(val) LOSS: 0.241709 | METRIC: 0.9083\n",
      "EPOCH: 82 | LRs: {0.007936594698349795}\n",
      "(trn) LOSS: 0.23288 | METRIC: 0.91736\n",
      "(val) LOSS: 0.20057 | METRIC: 0.8955\n",
      "EPOCH: 83 | LRs: {0.0071001587328783635}\n",
      "(trn) LOSS: 0.219713 | METRIC: 0.92276\n",
      "(val) LOSS: 0.517169 | METRIC: 0.9162\n",
      "EPOCH: 84 | LRs: {0.006306919472482149}\n",
      "(trn) LOSS: 0.211734 | METRIC: 0.92516\n",
      "(val) LOSS: 0.165781 | METRIC: 0.9172\n",
      "EPOCH: 85 | LRs: {0.00555767564185635}\n",
      "(trn) LOSS: 0.195835 | METRIC: 0.9308\n",
      "(val) LOSS: 0.154915 | METRIC: 0.9146\n",
      "EPOCH: 86 | LRs: {0.004853181666027719}\n",
      "(trn) LOSS: 0.180202 | METRIC: 0.937\n",
      "(val) LOSS: 0.087508 | METRIC: 0.9264\n",
      "EPOCH: 87 | LRs: {0.004194146910712534}\n",
      "(trn) LOSS: 0.168997 | METRIC: 0.9412\n",
      "(val) LOSS: 0.109562 | METRIC: 0.9242\n",
      "EPOCH: 88 | LRs: {0.0035812349680454016}\n",
      "(trn) LOSS: 0.155942 | METRIC: 0.94528\n",
      "(val) LOSS: 0.237596 | METRIC: 0.9297\n",
      "EPOCH: 89 | LRs: {0.00301506298839827}\n",
      "(trn) LOSS: 0.142435 | METRIC: 0.95012\n",
      "(val) LOSS: 0.661242 | METRIC: 0.9239\n",
      "EPOCH: 90 | LRs: {0.0024962010589623007}\n",
      "(trn) LOSS: 0.138356 | METRIC: 0.95256\n",
      "(val) LOSS: 0.456529 | METRIC: 0.9312\n",
      "EPOCH: 91 | LRs: {0.0020251716297183904}\n",
      "(trn) LOSS: 0.128159 | METRIC: 0.955\n",
      "(val) LOSS: 0.123288 | METRIC: 0.9332\n",
      "EPOCH: 92 | LRs: {0.0016024489873743427}\n",
      "(trn) LOSS: 0.120614 | METRIC: 0.95782\n",
      "(val) LOSS: 0.05046 | METRIC: 0.9297\n",
      "EPOCH: 93 | LRs: {0.0012284587777983227}\n",
      "(trn) LOSS: 0.110506 | METRIC: 0.96172\n",
      "(val) LOSS: 0.211761 | METRIC: 0.9345\n",
      "EPOCH: 94 | LRs: {0.0009035775774295846}\n",
      "(trn) LOSS: 0.104786 | METRIC: 0.96354\n",
      "(val) LOSS: 0.249606 | METRIC: 0.9351\n",
      "EPOCH: 95 | LRs: {0.0006281325140978953}\n",
      "(trn) LOSS: 0.099372 | METRIC: 0.96522\n",
      "(val) LOSS: 0.130237 | METRIC: 0.9334\n",
      "EPOCH: 96 | LRs: {0.00040240093763356006}\n",
      "(trn) LOSS: 0.094529 | METRIC: 0.96716\n",
      "(val) LOSS: 0.055733 | METRIC: 0.9337\n",
      "EPOCH: 97 | LRs: {0.00022661014059962645}\n",
      "(trn) LOSS: 0.089804 | METRIC: 0.96894\n",
      "(val) LOSS: 0.063248 | METRIC: 0.9346\n",
      "EPOCH: 98 | LRs: {0.00010093712942756166}\n",
      "(trn) LOSS: 0.093141 | METRIC: 0.9674\n",
      "(val) LOSS: 0.242185 | METRIC: 0.9337\n",
      "EPOCH: 99 | LRs: {2.5508446186774587e-05}\n",
      "(trn) LOSS: 0.092772 | METRIC: 0.96806\n",
      "(val) LOSS: 0.023004 | METRIC: 0.9355\n",
      "Best Val Score: 0.9355\n",
      "Runtime: 14313\n"
     ]
    }
   ],
   "source": [
    "!python train.py --logdir convratio0.875 --patch_size 2 --epochs 100 --rel_pos 1 \\\n",
    "--rel_pos_mul 0 --n_out_convs 0 --squeeze_conv 1 --linformer 0 --conv_ratio 0.875 --n_mid_convs 6 \\\n",
    "--sep_conv 0 --dim 288 --mlp_dim_mul 2 --depth 3 --heads 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train Samples: 50000 | # Val Samples: 10000\n",
      "# Parameters: 11150254\n",
      "EPOCH: 0 | LRs: {0.0040000000000000036}\n",
      "/home/kimyoonsoo/projects/vit/model.py:19: UserWarning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629395347/work/aten/src/ATen/native/TensorIterator.cpp:918.)\n",
      "  return self.fn(x, **kwargs) + x\n",
      "[W TensorIterator.cpp:924] Warning: Mixed memory format inputs detected while calling the operator. The operator will output channels_last tensor even if some of the inputs are not in channels_last format. (function operator())\n",
      "(trn) LOSS: 1.777033 | METRIC: 0.34828\n",
      "(val) LOSS: 1.697605 | METRIC: 0.4305\n",
      "Runtime: 148\n",
      "EPOCH: 1 | LRs: {0.05204823941842234}\n",
      "(trn) LOSS: 1.58349 | METRIC: 0.42062\n",
      "(val) LOSS: 1.467034 | METRIC: 0.5228\n",
      "Runtime: 149\n",
      "EPOCH: 2 | LRs: {0.0999999999579881}\n",
      "(trn) LOSS: 1.455516 | METRIC: 0.47254\n",
      "(val) LOSS: 1.601786 | METRIC: 0.5083\n",
      "EPOCH: 3 | LRs: {0.09997424517543715}\n",
      "(trn) LOSS: 1.341735 | METRIC: 0.51808\n",
      "(val) LOSS: 1.138569 | METRIC: 0.5849\n",
      "EPOCH: 4 | LRs: {0.09989713868329173}\n",
      "(trn) LOSS: 1.263174 | METRIC: 0.54714\n",
      "(val) LOSS: 0.946322 | METRIC: 0.5646\n",
      "EPOCH: 5 | LRs: {0.09976875971368483}\n",
      "(trn) LOSS: 1.202183 | METRIC: 0.5709\n",
      "(val) LOSS: 1.076136 | METRIC: 0.6627\n",
      "EPOCH: 6 | LRs: {0.09958924018468594}\n",
      "(trn) LOSS: 1.137641 | METRIC: 0.59788\n",
      "(val) LOSS: 1.307625 | METRIC: 0.6646\n",
      "EPOCH: 7 | LRs: {0.09935876456474639}\n",
      "(trn) LOSS: 1.093639 | METRIC: 0.61536\n",
      "(val) LOSS: 1.424642 | METRIC: 0.6652\n",
      "EPOCH: 8 | LRs: {0.0990775696831455}\n",
      "(trn) LOSS: 1.050918 | METRIC: 0.63162\n",
      "(val) LOSS: 0.967549 | METRIC: 0.7134\n",
      "EPOCH: 9 | LRs: {0.09874594448663251}\n",
      "(trn) LOSS: 1.017752 | METRIC: 0.64408\n",
      "(val) LOSS: 1.641543 | METRIC: 0.6794\n",
      "EPOCH: 10 | LRs: {0.09836422974251424}\n",
      "(trn) LOSS: 0.989993 | METRIC: 0.65582\n",
      "(val) LOSS: 0.545287 | METRIC: 0.6453\n",
      "EPOCH: 11 | LRs: {0.09793281768849367}\n",
      "(trn) LOSS: 0.959791 | METRIC: 0.66392\n",
      "(val) LOSS: 0.815576 | METRIC: 0.6704\n",
      "EPOCH: 12 | LRs: {0.09745215162961915}\n",
      "(trn) LOSS: 0.9415 | METRIC: 0.67408\n",
      "(val) LOSS: 1.724264 | METRIC: 0.6624\n",
      "EPOCH: 13 | LRs: {0.09692272548275854}\n",
      "(trn) LOSS: 0.91495 | METRIC: 0.68368\n",
      "(val) LOSS: 0.690646 | METRIC: 0.7143\n",
      "EPOCH: 14 | LRs: {0.09634508326906624}\n",
      "(trn) LOSS: 0.892164 | METRIC: 0.69034\n",
      "(val) LOSS: 0.93194 | METRIC: 0.7453\n",
      "EPOCH: 15 | LRs: {0.09571981855496461}\n",
      "(trn) LOSS: 0.87214 | METRIC: 0.69626\n",
      "(val) LOSS: 0.840246 | METRIC: 0.7217\n",
      "EPOCH: 16 | LRs: {0.09504757384221446}\n",
      "(trn) LOSS: 0.855714 | METRIC: 0.7032\n",
      "(val) LOSS: 1.061504 | METRIC: 0.7347\n",
      "EPOCH: 17 | LRs: {0.09432903990770092}\n",
      "(trn) LOSS: 0.836265 | METRIC: 0.7122\n",
      "(val) LOSS: 0.708074 | METRIC: 0.7813\n",
      "EPOCH: 18 | LRs: {0.09356495509361362}\n",
      "(trn) LOSS: 0.819453 | METRIC: 0.71602\n",
      "(val) LOSS: 0.790564 | METRIC: 0.759\n",
      "EPOCH: 19 | LRs: {0.09275610454875012}\n",
      "(trn) LOSS: 0.802136 | METRIC: 0.72382\n",
      "(val) LOSS: 1.186571 | METRIC: 0.7687\n",
      "EPOCH: 20 | LRs: {0.09190331942172247}\n",
      "(trn) LOSS: 0.788813 | METRIC: 0.72976\n",
      "(val) LOSS: 0.526171 | METRIC: 0.7775\n",
      "EPOCH: 21 | LRs: {0.09100747600689577}\n",
      "(trn) LOSS: 0.768944 | METRIC: 0.73444\n",
      "(val) LOSS: 0.509846 | METRIC: 0.8097\n",
      "EPOCH: 22 | LRs: {0.09006949484393653}\n",
      "(trn) LOSS: 0.756293 | METRIC: 0.7413\n",
      "(val) LOSS: 0.947997 | METRIC: 0.7918\n",
      "EPOCH: 23 | LRs: {0.08909033977189595}\n",
      "(trn) LOSS: 0.748634 | METRIC: 0.74318\n",
      "(val) LOSS: 0.446706 | METRIC: 0.7761\n",
      "EPOCH: 24 | LRs: {0.08807101693880005}\n",
      "(trn) LOSS: 0.73839 | METRIC: 0.74696\n",
      "(val) LOSS: 0.678966 | METRIC: 0.7619\n",
      "EPOCH: 25 | LRs: {0.08701257376776472}\n",
      "(trn) LOSS: 0.724803 | METRIC: 0.7494\n",
      "(val) LOSS: 0.51426 | METRIC: 0.7986\n",
      "EPOCH: 26 | LRs: {0.08591609788069746}\n",
      "(trn) LOSS: 0.716048 | METRIC: 0.75704\n",
      "(val) LOSS: 0.661585 | METRIC: 0.8016\n",
      "EPOCH: 27 | LRs: {0.08478271598069248}\n",
      "(trn) LOSS: 0.708054 | METRIC: 0.75896\n",
      "(val) LOSS: 0.345727 | METRIC: 0.8119\n",
      "EPOCH: 28 | LRs: {0.08361359269426712}\n",
      "(trn) LOSS: 0.696727 | METRIC: 0.76172\n",
      "(val) LOSS: 1.259013 | METRIC: 0.7861\n",
      "EPOCH: 29 | LRs: {0.08240992937462929}\n",
      "(trn) LOSS: 0.687945 | METRIC: 0.76148\n",
      "(val) LOSS: 0.425202 | METRIC: 0.801\n",
      "EPOCH: 30 | LRs: {0.0811729628672059}\n",
      "(trn) LOSS: 0.673327 | METRIC: 0.76946\n",
      "(val) LOSS: 0.436018 | METRIC: 0.776\n",
      "EPOCH: 31 | LRs: {0.0799039642387006}\n",
      "(trn) LOSS: 0.661471 | METRIC: 0.7739\n",
      "(val) LOSS: 0.774842 | METRIC: 0.8213\n",
      "EPOCH: 32 | LRs: {0.0786042374709867}\n",
      "(trn) LOSS: 0.661712 | METRIC: 0.77348\n",
      "(val) LOSS: 0.220559 | METRIC: 0.8215\n",
      "EPOCH: 33 | LRs: {0.07727511812117777}\n",
      "(trn) LOSS: 0.656054 | METRIC: 0.7749\n",
      "(val) LOSS: 0.569082 | METRIC: 0.7754\n",
      "EPOCH: 34 | LRs: {0.07591797194925239}\n",
      "(trn) LOSS: 0.637989 | METRIC: 0.7811\n",
      "(val) LOSS: 0.506773 | METRIC: 0.7981\n",
      "EPOCH: 35 | LRs: {0.07453419351464342}\n",
      "(trn) LOSS: 0.639314 | METRIC: 0.78006\n",
      "(val) LOSS: 0.254367 | METRIC: 0.8328\n",
      "EPOCH: 36 | LRs: {0.07312520474323396}\n",
      "(trn) LOSS: 0.621874 | METRIC: 0.78454\n",
      "(val) LOSS: 0.672953 | METRIC: 0.7968\n",
      "EPOCH: 37 | LRs: {0.07169245346623233}\n",
      "(trn) LOSS: 0.616573 | METRIC: 0.78768\n",
      "(val) LOSS: 0.403947 | METRIC: 0.8445\n",
      "EPOCH: 38 | LRs: {0.07023741193242763}\n",
      "(trn) LOSS: 0.611625 | METRIC: 0.78876\n",
      "(val) LOSS: 1.242692 | METRIC: 0.8084\n",
      "EPOCH: 39 | LRs: {0.06876157529535469}\n",
      "(trn) LOSS: 0.60476 | METRIC: 0.793\n",
      "(val) LOSS: 0.303825 | METRIC: 0.8434\n",
      "EPOCH: 40 | LRs: {0.06726646007692261}\n",
      "(trn) LOSS: 0.594551 | METRIC: 0.79638\n",
      "(val) LOSS: 0.825934 | METRIC: 0.8288\n",
      "EPOCH: 41 | LRs: {0.06575360260908605}\n",
      "(trn) LOSS: 0.596018 | METRIC: 0.79546\n",
      "(val) LOSS: 0.594452 | METRIC: 0.8064\n",
      "EPOCH: 42 | LRs: {0.06422455745516034}\n",
      "(trn) LOSS: 0.583124 | METRIC: 0.7982\n",
      "(val) LOSS: 0.907515 | METRIC: 0.8423\n",
      "EPOCH: 43 | LRs: {0.06268089581240244}\n",
      "(trn) LOSS: 0.571284 | METRIC: 0.80376\n",
      "(val) LOSS: 0.572456 | METRIC: 0.8013\n",
      "EPOCH: 44 | LRs: {0.061124203897499695}\n",
      "(trn) LOSS: 0.568729 | METRIC: 0.80608\n",
      "(val) LOSS: 0.358099 | METRIC: 0.8113\n",
      "EPOCH: 45 | LRs: {0.05955608131662491}\n",
      "(trn) LOSS: 0.566046 | METRIC: 0.8043\n",
      "(val) LOSS: 0.061392 | METRIC: 0.8155\n",
      "EPOCH: 46 | LRs: {0.05797813942173288}\n",
      "(trn) LOSS: 0.562703 | METRIC: 0.80742\n",
      "(val) LOSS: 0.171404 | METRIC: 0.8255\n",
      "EPOCH: 47 | LRs: {0.05639199965478729}\n",
      "(trn) LOSS: 0.554385 | METRIC: 0.80946\n",
      "(val) LOSS: 0.602826 | METRIC: 0.8662\n",
      "EPOCH: 48 | LRs: {0.054799291881619534}\n",
      "(trn) LOSS: 0.544866 | METRIC: 0.8143\n",
      "(val) LOSS: 0.459469 | METRIC: 0.8495\n",
      "EPOCH: 49 | LRs: {0.053201652717131405}\n",
      "(trn) LOSS: 0.545838 | METRIC: 0.81152\n",
      "(val) LOSS: 0.568044 | METRIC: 0.8285\n",
      "EPOCH: 50 | LRs: {0.051600723843562624}\n",
      "(trn) LOSS: 0.535285 | METRIC: 0.81654\n",
      "(val) LOSS: 0.802114 | METRIC: 0.8473\n",
      "EPOCH: 51 | LRs: {0.04999815032355138}\n",
      "(trn) LOSS: 0.529586 | METRIC: 0.8168\n",
      "(val) LOSS: 0.250727 | METRIC: 0.8647\n",
      "EPOCH: 52 | LRs: {0.04839557890972123}\n",
      "(trn) LOSS: 0.517423 | METRIC: 0.82356\n",
      "(val) LOSS: 0.359225 | METRIC: 0.8515\n",
      "EPOCH: 53 | LRs: {0.04679465635253152}\n",
      "(trn) LOSS: 0.513798 | METRIC: 0.82254\n",
      "(val) LOSS: 0.755583 | METRIC: 0.8582\n",
      "EPOCH: 54 | LRs: {0.045197027708129944}\n",
      "(trn) LOSS: 0.502882 | METRIC: 0.82616\n",
      "(val) LOSS: 0.285137 | METRIC: 0.8457\n",
      "EPOCH: 55 | LRs: {0.0436043346479461}\n",
      "(trn) LOSS: 0.499349 | METRIC: 0.8266\n",
      "(val) LOSS: 0.325192 | METRIC: 0.854\n",
      "EPOCH: 56 | LRs: {0.04201821377176317}\n",
      "(trn) LOSS: 0.489259 | METRIC: 0.83112\n",
      "(val) LOSS: 0.3963 | METRIC: 0.8636\n",
      "EPOCH: 57 | LRs: {0.04044029492600105}\n",
      "(trn) LOSS: 0.483748 | METRIC: 0.83286\n",
      "(val) LOSS: 0.612112 | METRIC: 0.8693\n",
      "EPOCH: 58 | LRs: {0.03887219952893889}\n",
      "(trn) LOSS: 0.476918 | METRIC: 0.8356\n",
      "(val) LOSS: 0.386437 | METRIC: 0.867\n",
      "EPOCH: 59 | LRs: {0.03731553890459829}\n",
      "(trn) LOSS: 0.472647 | METRIC: 0.83662\n",
      "(val) LOSS: 0.260783 | METRIC: 0.8739\n",
      "EPOCH: 60 | LRs: {0.035771912626998824}\n",
      "(trn) LOSS: 0.459512 | METRIC: 0.84088\n",
      "(val) LOSS: 0.216466 | METRIC: 0.8566\n",
      "EPOCH: 61 | LRs: {0.03424290687648778}\n",
      "(trn) LOSS: 0.448353 | METRIC: 0.8459\n",
      "(val) LOSS: 0.402641 | METRIC: 0.8587\n",
      "EPOCH: 62 | LRs: {0.03273009280983248}\n",
      "(trn) LOSS: 0.442733 | METRIC: 0.84716\n",
      "(val) LOSS: 0.198168 | METRIC: 0.8831\n",
      "EPOCH: 63 | LRs: {0.031235024945750582}\n",
      "(trn) LOSS: 0.434397 | METRIC: 0.84914\n",
      "(val) LOSS: 0.131865 | METRIC: 0.8777\n",
      "EPOCH: 64 | LRs: {0.029759239567536944}\n",
      "(trn) LOSS: 0.42666 | METRIC: 0.852\n",
      "(val) LOSS: 0.453931 | METRIC: 0.8823\n",
      "EPOCH: 65 | LRs: {0.028304253144428713}\n",
      "(trn) LOSS: 0.413822 | METRIC: 0.8568\n",
      "(val) LOSS: 0.32722 | METRIC: 0.8707\n",
      "EPOCH: 66 | LRs: {0.026871560773330767}\n",
      "(trn) LOSS: 0.404511 | METRIC: 0.85936\n",
      "(val) LOSS: 0.111438 | METRIC: 0.8766\n",
      "EPOCH: 67 | LRs: {0.02546263464250241}\n",
      "(trn) LOSS: 0.396411 | METRIC: 0.86314\n",
      "(val) LOSS: 0.318626 | METRIC: 0.864\n",
      "EPOCH: 68 | LRs: {0.02407892251878453}\n",
      "(trn) LOSS: 0.390449 | METRIC: 0.86522\n",
      "(val) LOSS: 0.889008 | METRIC: 0.8815\n",
      "EPOCH: 69 | LRs: {0.022721846259921304}\n",
      "(trn) LOSS: 0.379062 | METRIC: 0.86798\n",
      "(val) LOSS: 0.452306 | METRIC: 0.8586\n",
      "EPOCH: 70 | LRs: {0.021392800353505197}\n",
      "(trn) LOSS: 0.363526 | METRIC: 0.87354\n",
      "(val) LOSS: 0.396219 | METRIC: 0.8803\n",
      "EPOCH: 71 | LRs: {0.020093150484046713}\n",
      "(trn) LOSS: 0.356763 | METRIC: 0.87614\n",
      "(val) LOSS: 0.570201 | METRIC: 0.8917\n",
      "EPOCH: 72 | LRs: {0.018824232129641284}\n",
      "(trn) LOSS: 0.348169 | METRIC: 0.87864\n",
      "(val) LOSS: 0.14972 | METRIC: 0.8921\n",
      "EPOCH: 73 | LRs: {0.01758734918967517}\n",
      "(trn) LOSS: 0.334968 | METRIC: 0.8834\n",
      "(val) LOSS: 0.386765 | METRIC: 0.9014\n",
      "EPOCH: 74 | LRs: {0.016383772644980827}\n",
      "(trn) LOSS: 0.324914 | METRIC: 0.88582\n",
      "(val) LOSS: 0.197129 | METRIC: 0.903\n",
      "EPOCH: 75 | LRs: {0.015214739251817981}\n",
      "(trn) LOSS: 0.309823 | METRIC: 0.89124\n",
      "(val) LOSS: 0.723429 | METRIC: 0.9111\n",
      "EPOCH: 76 | LRs: {0.014081450271023173}\n",
      "(trn) LOSS: 0.298763 | METRIC: 0.8953\n",
      "(val) LOSS: 0.166102 | METRIC: 0.9102\n",
      "EPOCH: 77 | LRs: {0.012985070233632972}\n",
      "(trn) LOSS: 0.286576 | METRIC: 0.90018\n",
      "(val) LOSS: 0.651695 | METRIC: 0.9056\n",
      "EPOCH: 78 | LRs: {0.01192672574424955}\n",
      "(trn) LOSS: 0.275346 | METRIC: 0.90462\n",
      "(val) LOSS: 0.062351 | METRIC: 0.9086\n",
      "EPOCH: 79 | LRs: {0.010907504323378406}\n",
      "(trn) LOSS: 0.263969 | METRIC: 0.90526\n",
      "(val) LOSS: 0.266559 | METRIC: 0.9053\n",
      "EPOCH: 80 | LRs: {0.009928453289927433}\n",
      "(trn) LOSS: 0.247524 | METRIC: 0.91332\n",
      "(val) LOSS: 0.051702 | METRIC: 0.9082\n",
      "EPOCH: 81 | LRs: {0.008990578685016}\n",
      "(trn) LOSS: 0.23706 | METRIC: 0.9166\n",
      "(val) LOSS: 0.172576 | METRIC: 0.9039\n",
      "EPOCH: 82 | LRs: {0.008094844238199707}\n",
      "(trn) LOSS: 0.224069 | METRIC: 0.9214\n",
      "(val) LOSS: 0.279994 | METRIC: 0.9175\n",
      "EPOCH: 83 | LRs: {0.00724217037717306}\n",
      "(trn) LOSS: 0.21 | METRIC: 0.9258\n",
      "(val) LOSS: 0.291024 | METRIC: 0.9175\n",
      "EPOCH: 84 | LRs: {0.006433433281967851}\n",
      "(trn) LOSS: 0.198398 | METRIC: 0.92992\n",
      "(val) LOSS: 0.201635 | METRIC: 0.9193\n",
      "EPOCH: 85 | LRs: {0.005669463984618912}\n",
      "(trn) LOSS: 0.18442 | METRIC: 0.9352\n",
      "(val) LOSS: 0.095418 | METRIC: 0.924\n",
      "EPOCH: 86 | LRs: {0.004951047515222534}\n",
      "(trn) LOSS: 0.171744 | METRIC: 0.9412\n",
      "(val) LOSS: 0.608496 | METRIC: 0.9231\n",
      "EPOCH: 87 | LRs: {0.004278922095265002}\n",
      "(trn) LOSS: 0.155621 | METRIC: 0.94586\n",
      "(val) LOSS: 0.115439 | METRIC: 0.9267\n",
      "EPOCH: 88 | LRs: {0.003653778379050075}\n",
      "(trn) LOSS: 0.149929 | METRIC: 0.94722\n",
      "(val) LOSS: 0.015462 | METRIC: 0.9282\n",
      "EPOCH: 89 | LRs: {0.0030762587440050083}\n",
      "(trn) LOSS: 0.135674 | METRIC: 0.95192\n",
      "(val) LOSS: 0.152549 | METRIC: 0.9257\n",
      "EPOCH: 90 | LRs: {0.0025469566305943553}\n",
      "(trn) LOSS: 0.127865 | METRIC: 0.95458\n",
      "(val) LOSS: 0.295421 | METRIC: 0.9293\n",
      "EPOCH: 91 | LRs: {0.0020664159325197305}\n",
      "(trn) LOSS: 0.11563 | METRIC: 0.95954\n",
      "(val) LOSS: 0.010047 | METRIC: 0.9316\n",
      "EPOCH: 92 | LRs: {0.0016351304378323086}\n",
      "(trn) LOSS: 0.111318 | METRIC: 0.96122\n",
      "(val) LOSS: 0.13634 | METRIC: 0.9292\n",
      "EPOCH: 93 | LRs: {0.001253543321532178}\n",
      "(trn) LOSS: 0.102608 | METRIC: 0.964\n",
      "(val) LOSS: 0.010458 | METRIC: 0.9356\n",
      "EPOCH: 94 | LRs: {0.0009220466901760982}\n",
      "(trn) LOSS: 0.09649 | METRIC: 0.96654\n",
      "(val) LOSS: 0.154764 | METRIC: 0.9372\n",
      "EPOCH: 95 | LRs: {0.0006409811789615092}\n",
      "(trn) LOSS: 0.091838 | METRIC: 0.96782\n",
      "(val) LOSS: 0.113089 | METRIC: 0.937\n",
      "EPOCH: 96 | LRs: {0.00041063560170082633}\n",
      "(trn) LOSS: 0.089991 | METRIC: 0.96924\n",
      "(val) LOSS: 0.006369 | METRIC: 0.9387\n",
      "EPOCH: 97 | LRs: {0.0002312466540457233}\n",
      "(trn) LOSS: 0.088835 | METRIC: 0.9691\n",
      "(val) LOSS: 0.097255 | METRIC: 0.9386\n",
      "EPOCH: 98 | LRs: {0.00010299867026636821}\n",
      "(trn) LOSS: 0.085812 | METRIC: 0.97068\n",
      "(val) LOSS: 0.076595 | METRIC: 0.936\n",
      "EPOCH: 99 | LRs: {2.6023433835476683e-05}\n",
      "(trn) LOSS: 0.085324 | METRIC: 0.97008\n",
      "(val) LOSS: 0.03128 | METRIC: 0.9372\n",
      "Best Val Score: 0.9387\n",
      "Runtime: 14958\n"
     ]
    }
   ],
   "source": [
    "!python train.py --logdir convratio0.75 --patch_size 2 --epochs 100 --rel_pos 1 \\\n",
    "--rel_pos_mul 0 --n_out_convs 0 --squeeze_conv 1 --linformer 0 --conv_ratio 0.75 --n_mid_convs 6 \\\n",
    "--sep_conv 0 --dim 336 --mlp_dim_mul 2 --depth 3 --heads 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train Samples: 50000 | # Val Samples: 10000\n",
      "# Parameters: 10811674\n",
      "EPOCH: 0 | LRs: {0.0040000000000000036}\n",
      "/home/kimyoonsoo/projects/vit/model.py:19: UserWarning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629395347/work/aten/src/ATen/native/TensorIterator.cpp:918.)\n",
      "  return self.fn(x, **kwargs) + x\n",
      "[W TensorIterator.cpp:924] Warning: Mixed memory format inputs detected while calling the operator. The operator will output channels_last tensor even if some of the inputs are not in channels_last format. (function operator())\n",
      "(trn) LOSS: 1.760862 | METRIC: 0.35406\n",
      "(val) LOSS: 1.694129 | METRIC: 0.4769\n",
      "Runtime: 147\n",
      "EPOCH: 1 | LRs: {0.02801856579744566}\n",
      "(trn) LOSS: 1.558104 | METRIC: 0.4295\n",
      "(val) LOSS: 1.839689 | METRIC: 0.5349\n",
      "Runtime: 145\n",
      "EPOCH: 2 | LRs: {0.07603711723285653}\n",
      "(trn) LOSS: 1.516377 | METRIC: 0.45786\n",
      "(val) LOSS: 1.67211 | METRIC: 0.52\n",
      "EPOCH: 3 | LRs: {0.09999999995711742}\n",
      "(trn) LOSS: 1.357257 | METRIC: 0.51586\n",
      "(val) LOSS: 1.003421 | METRIC: 0.593\n",
      "EPOCH: 4 | LRs: {0.09997371145765042}\n",
      "(trn) LOSS: 1.264724 | METRIC: 0.54928\n",
      "(val) LOSS: 1.373756 | METRIC: 0.6226\n",
      "EPOCH: 5 | LRs: {0.09989500764555803}\n",
      "(trn) LOSS: 1.202195 | METRIC: 0.56964\n",
      "(val) LOSS: 0.868896 | METRIC: 0.6335\n",
      "EPOCH: 6 | LRs: {0.09976397107027081}\n",
      "(trn) LOSS: 1.138236 | METRIC: 0.59858\n",
      "(val) LOSS: 0.827474 | METRIC: 0.5992\n",
      "EPOCH: 7 | LRs: {0.09958073917106126}\n",
      "(trn) LOSS: 1.096558 | METRIC: 0.61422\n",
      "(val) LOSS: 0.994283 | METRIC: 0.6476\n",
      "EPOCH: 8 | LRs: {0.09934550413288899}\n",
      "(trn) LOSS: 1.047109 | METRIC: 0.6347\n",
      "(val) LOSS: 1.011216 | METRIC: 0.6243\n",
      "EPOCH: 9 | LRs: {0.0990585126848252}\n",
      "(trn) LOSS: 1.022127 | METRIC: 0.6452\n",
      "(val) LOSS: 0.43837 | METRIC: 0.6765\n",
      "EPOCH: 10 | LRs: {0.09872006584126793}\n",
      "(trn) LOSS: 0.977329 | METRIC: 0.66016\n",
      "(val) LOSS: 0.53523 | METRIC: 0.7332\n",
      "EPOCH: 11 | LRs: {0.09833051858621962}\n",
      "(trn) LOSS: 0.953995 | METRIC: 0.66912\n",
      "(val) LOSS: 0.965614 | METRIC: 0.7499\n",
      "EPOCH: 12 | LRs: {0.09789027950095783}\n",
      "(trn) LOSS: 0.918239 | METRIC: 0.68244\n",
      "(val) LOSS: 1.110426 | METRIC: 0.746\n",
      "EPOCH: 13 | LRs: {0.09739981033548992}\n",
      "(trn) LOSS: 0.900657 | METRIC: 0.6859\n",
      "(val) LOSS: 1.642239 | METRIC: 0.7677\n",
      "EPOCH: 14 | LRs: {0.0968596255242411}\n",
      "(trn) LOSS: 0.882868 | METRIC: 0.69474\n",
      "(val) LOSS: 1.465177 | METRIC: 0.7008\n",
      "EPOCH: 15 | LRs: {0.09627029164648368}\n",
      "(trn) LOSS: 0.86152 | METRIC: 0.70278\n",
      "(val) LOSS: 0.598539 | METRIC: 0.7433\n",
      "EPOCH: 16 | LRs: {0.0956324268320737}\n",
      "(trn) LOSS: 0.837565 | METRIC: 0.71058\n",
      "(val) LOSS: 0.777977 | METRIC: 0.7779\n",
      "EPOCH: 17 | LRs: {0.09494670011311805}\n",
      "(trn) LOSS: 0.813834 | METRIC: 0.71886\n",
      "(val) LOSS: 0.548395 | METRIC: 0.7663\n",
      "EPOCH: 18 | LRs: {0.09421383072225226}\n",
      "(trn) LOSS: 0.798949 | METRIC: 0.72358\n",
      "(val) LOSS: 0.821985 | METRIC: 0.7656\n",
      "EPOCH: 19 | LRs: {0.0934345873382646}\n",
      "(trn) LOSS: 0.783575 | METRIC: 0.7307\n",
      "(val) LOSS: 0.694774 | METRIC: 0.7623\n",
      "EPOCH: 20 | LRs: {0.09260978727985839}\n",
      "(trn) LOSS: 0.764082 | METRIC: 0.73698\n",
      "(val) LOSS: 1.076963 | METRIC: 0.7916\n",
      "EPOCH: 21 | LRs: {0.09174029564839739}\n",
      "(trn) LOSS: 0.754946 | METRIC: 0.73804\n",
      "(val) LOSS: 0.177005 | METRIC: 0.7691\n",
      "EPOCH: 22 | LRs: {0.09082702442053402}\n",
      "(trn) LOSS: 0.737772 | METRIC: 0.74478\n",
      "(val) LOSS: 0.641527 | METRIC: 0.7913\n",
      "EPOCH: 23 | LRs: {0.08987093149167172}\n",
      "(trn) LOSS: 0.724231 | METRIC: 0.75298\n",
      "(val) LOSS: 0.936898 | METRIC: 0.7864\n",
      "EPOCH: 24 | LRs: {0.08887301967126505}\n",
      "(trn) LOSS: 0.713573 | METRIC: 0.75406\n",
      "(val) LOSS: 0.311486 | METRIC: 0.8097\n",
      "EPOCH: 25 | LRs: {0.08783433563101091}\n",
      "(trn) LOSS: 0.694214 | METRIC: 0.75922\n",
      "(val) LOSS: 0.569209 | METRIC: 0.7842\n",
      "EPOCH: 26 | LRs: {0.08675596880703458}\n",
      "(trn) LOSS: 0.697049 | METRIC: 0.76144\n",
      "(val) LOSS: 0.373954 | METRIC: 0.8246\n",
      "EPOCH: 27 | LRs: {0.08563905025722167}\n",
      "(trn) LOSS: 0.679928 | METRIC: 0.76594\n",
      "(val) LOSS: 0.544876 | METRIC: 0.8089\n",
      "EPOCH: 28 | LRs: {0.08448475147489444}\n",
      "(trn) LOSS: 0.673029 | METRIC: 0.76906\n",
      "(val) LOSS: 0.779644 | METRIC: 0.7854\n",
      "EPOCH: 29 | LRs: {0.08329428316007728}\n",
      "(trn) LOSS: 0.665927 | METRIC: 0.77002\n",
      "(val) LOSS: 1.049522 | METRIC: 0.8029\n",
      "EPOCH: 30 | LRs: {0.08206889394963943}\n",
      "(trn) LOSS: 0.658254 | METRIC: 0.77486\n",
      "(val) LOSS: 1.277286 | METRIC: 0.8114\n",
      "EPOCH: 31 | LRs: {0.08080986910764738}\n",
      "(trn) LOSS: 0.645917 | METRIC: 0.77898\n",
      "(val) LOSS: 0.460623 | METRIC: 0.8022\n",
      "EPOCH: 32 | LRs: {0.07951852917730035}\n",
      "(trn) LOSS: 0.639621 | METRIC: 0.78014\n",
      "(val) LOSS: 0.698946 | METRIC: 0.8356\n",
      "EPOCH: 33 | LRs: {0.0781962285958628}\n",
      "(trn) LOSS: 0.629641 | METRIC: 0.78438\n",
      "(val) LOSS: 0.684026 | METRIC: 0.8389\n",
      "EPOCH: 34 | LRs: {0.0768443542740468}\n",
      "(trn) LOSS: 0.617723 | METRIC: 0.78794\n",
      "(val) LOSS: 0.711778 | METRIC: 0.8312\n",
      "EPOCH: 35 | LRs: {0.07546432414133426}\n",
      "(trn) LOSS: 0.614607 | METRIC: 0.79106\n",
      "(val) LOSS: 0.448855 | METRIC: 0.7769\n",
      "EPOCH: 36 | LRs: {0.07405758565876457}\n",
      "(trn) LOSS: 0.609631 | METRIC: 0.7923\n",
      "(val) LOSS: 0.914677 | METRIC: 0.8258\n",
      "EPOCH: 37 | LRs: {0.072625614300748}\n",
      "(trn) LOSS: 0.59625 | METRIC: 0.79636\n",
      "(val) LOSS: 0.71862 | METRIC: 0.8524\n",
      "EPOCH: 38 | LRs: {0.07116991200749671}\n",
      "(trn) LOSS: 0.594568 | METRIC: 0.79798\n",
      "(val) LOSS: 0.869613 | METRIC: 0.8148\n",
      "EPOCH: 39 | LRs: {0.06969200560969689}\n",
      "(trn) LOSS: 0.583365 | METRIC: 0.79858\n",
      "(val) LOSS: 0.777584 | METRIC: 0.8238\n",
      "EPOCH: 40 | LRs: {0.0681934452270742}\n",
      "(trn) LOSS: 0.581696 | METRIC: 0.80072\n",
      "(val) LOSS: 0.664331 | METRIC: 0.766\n",
      "EPOCH: 41 | LRs: {0.06667580264253227}\n",
      "(trn) LOSS: 0.577788 | METRIC: 0.8031\n",
      "(val) LOSS: 0.572829 | METRIC: 0.826\n",
      "EPOCH: 42 | LRs: {0.06514066965356949}\n",
      "(trn) LOSS: 0.573836 | METRIC: 0.80612\n",
      "(val) LOSS: 0.47189 | METRIC: 0.8221\n",
      "EPOCH: 43 | LRs: {0.06358965640270316}\n",
      "(trn) LOSS: 0.570504 | METRIC: 0.80558\n",
      "(val) LOSS: 0.208954 | METRIC: 0.8097\n",
      "EPOCH: 44 | LRs: {0.06202438968865241}\n",
      "(trn) LOSS: 0.551653 | METRIC: 0.81022\n",
      "(val) LOSS: 0.631206 | METRIC: 0.8022\n",
      "EPOCH: 45 | LRs: {0.06044651126005101}\n",
      "(trn) LOSS: 0.55155 | METRIC: 0.8099\n",
      "(val) LOSS: 0.53633 | METRIC: 0.8399\n",
      "EPOCH: 46 | LRs: {0.058857676093479694}\n",
      "(trn) LOSS: 0.54282 | METRIC: 0.81332\n",
      "(val) LOSS: 0.830212 | METRIC: 0.861\n",
      "EPOCH: 47 | LRs: {0.05725955065762431}\n",
      "(trn) LOSS: 0.542165 | METRIC: 0.81246\n",
      "(val) LOSS: 0.226997 | METRIC: 0.8659\n",
      "EPOCH: 48 | LRs: {0.05565381116538028}\n",
      "(trn) LOSS: 0.529435 | METRIC: 0.81862\n",
      "(val) LOSS: 0.805303 | METRIC: 0.8384\n",
      "EPOCH: 49 | LRs: {0.054042141815736765}\n",
      "(trn) LOSS: 0.530682 | METRIC: 0.81768\n",
      "(val) LOSS: 0.480973 | METRIC: 0.8157\n",
      "EPOCH: 50 | LRs: {0.052426233027284455}\n",
      "(trn) LOSS: 0.518875 | METRIC: 0.82148\n",
      "(val) LOSS: 0.559851 | METRIC: 0.8495\n",
      "EPOCH: 51 | LRs: {0.050807779665199906}\n",
      "(trn) LOSS: 0.510557 | METRIC: 0.82394\n",
      "(val) LOSS: 0.458656 | METRIC: 0.8499\n",
      "EPOCH: 52 | LRs: {0.04918847926356607}\n",
      "(trn) LOSS: 0.50938 | METRIC: 0.82526\n",
      "(val) LOSS: 0.939746 | METRIC: 0.8591\n",
      "EPOCH: 53 | LRs: {0.047570030244893424}\n",
      "(trn) LOSS: 0.501606 | METRIC: 0.8281\n",
      "(val) LOSS: 0.688696 | METRIC: 0.8527\n",
      "EPOCH: 54 | LRs: {0.04595413013870923}\n",
      "(trn) LOSS: 0.499805 | METRIC: 0.82844\n",
      "(val) LOSS: 0.601451 | METRIC: 0.8454\n",
      "EPOCH: 55 | LRs: {0.04434247380108356}\n",
      "(trn) LOSS: 0.483916 | METRIC: 0.83224\n",
      "(val) LOSS: 0.381784 | METRIC: 0.8621\n",
      "EPOCH: 56 | LRs: {0.042736751636959336}\n",
      "(trn) LOSS: 0.482155 | METRIC: 0.83376\n",
      "(val) LOSS: 0.346895 | METRIC: 0.8674\n",
      "EPOCH: 57 | LRs: {0.04113864782715087}\n",
      "(trn) LOSS: 0.47422 | METRIC: 0.83672\n",
      "(val) LOSS: 0.573272 | METRIC: 0.8573\n",
      "EPOCH: 58 | LRs: {0.039549838561870845}\n",
      "(trn) LOSS: 0.46294 | METRIC: 0.84106\n",
      "(val) LOSS: 1.366203 | METRIC: 0.8576\n",
      "EPOCH: 59 | LRs: {0.037971990282638264}\n",
      "(trn) LOSS: 0.45629 | METRIC: 0.84324\n",
      "(val) LOSS: 0.158092 | METRIC: 0.8714\n",
      "EPOCH: 60 | LRs: {0.036406757934411324}\n",
      "(trn) LOSS: 0.449658 | METRIC: 0.84648\n",
      "(val) LOSS: 1.048513 | METRIC: 0.8606\n",
      "EPOCH: 61 | LRs: {0.03485578322977876}\n",
      "(trn) LOSS: 0.448005 | METRIC: 0.84564\n",
      "(val) LOSS: 0.668254 | METRIC: 0.8548\n",
      "EPOCH: 62 | LRs: {0.03332069292703007}\n",
      "(trn) LOSS: 0.44029 | METRIC: 0.8484\n",
      "(val) LOSS: 0.390085 | METRIC: 0.8659\n",
      "EPOCH: 63 | LRs: {0.03180309712391062}\n",
      "(trn) LOSS: 0.422194 | METRIC: 0.85478\n",
      "(val) LOSS: 0.267431 | METRIC: 0.8649\n",
      "EPOCH: 64 | LRs: {0.03030458756885149}\n",
      "(trn) LOSS: 0.418296 | METRIC: 0.8568\n",
      "(val) LOSS: 0.245421 | METRIC: 0.862\n",
      "EPOCH: 65 | LRs: {0.028826735991445238}\n",
      "(trn) LOSS: 0.405848 | METRIC: 0.85942\n",
      "(val) LOSS: 0.336121 | METRIC: 0.8774\n",
      "EPOCH: 66 | LRs: {0.027371092453918514}\n",
      "(trn) LOSS: 0.402358 | METRIC: 0.86152\n",
      "(val) LOSS: 0.187539 | METRIC: 0.8902\n",
      "EPOCH: 67 | LRs: {0.025939183725330866}\n",
      "(trn) LOSS: 0.392856 | METRIC: 0.8633\n",
      "(val) LOSS: 0.395262 | METRIC: 0.8752\n",
      "EPOCH: 68 | LRs: {0.024532511680204826}\n",
      "(trn) LOSS: 0.387623 | METRIC: 0.86642\n",
      "(val) LOSS: 0.457137 | METRIC: 0.893\n",
      "EPOCH: 69 | LRs: {0.02315255172326695}\n",
      "(trn) LOSS: 0.375988 | METRIC: 0.86898\n",
      "(val) LOSS: 0.366227 | METRIC: 0.879\n",
      "EPOCH: 70 | LRs: {0.021800751241951962}\n",
      "(trn) LOSS: 0.369114 | METRIC: 0.87254\n",
      "(val) LOSS: 0.461376 | METRIC: 0.893\n",
      "EPOCH: 71 | LRs: {0.02047852808829325}\n",
      "(trn) LOSS: 0.353223 | METRIC: 0.8767\n",
      "(val) LOSS: 0.175147 | METRIC: 0.8813\n",
      "EPOCH: 72 | LRs: {0.01918726909179184}\n",
      "(trn) LOSS: 0.342642 | METRIC: 0.88236\n",
      "(val) LOSS: 0.147178 | METRIC: 0.8817\n",
      "EPOCH: 73 | LRs: {0.017928328604823785}\n",
      "(trn) LOSS: 0.33211 | METRIC: 0.8851\n",
      "(val) LOSS: 0.413679 | METRIC: 0.8984\n",
      "EPOCH: 74 | LRs: {0.016703027082111518}\n",
      "(trn) LOSS: 0.321273 | METRIC: 0.88818\n",
      "(val) LOSS: 0.5166 | METRIC: 0.901\n",
      "EPOCH: 75 | LRs: {0.01551264969574922}\n",
      "(trn) LOSS: 0.308869 | METRIC: 0.89312\n",
      "(val) LOSS: 0.286931 | METRIC: 0.903\n",
      "EPOCH: 76 | LRs: {0.014358444987234742}\n",
      "(trn) LOSS: 0.303765 | METRIC: 0.89422\n",
      "(val) LOSS: 0.520664 | METRIC: 0.8957\n",
      "EPOCH: 77 | LRs: {0.013241623557921998}\n",
      "(trn) LOSS: 0.285701 | METRIC: 0.9013\n",
      "(val) LOSS: 0.479198 | METRIC: 0.9103\n",
      "EPOCH: 78 | LRs: {0.012163356799267338}\n",
      "(trn) LOSS: 0.277616 | METRIC: 0.90386\n",
      "(val) LOSS: 0.248178 | METRIC: 0.9066\n",
      "EPOCH: 79 | LRs: {0.011124775664201572}\n",
      "(trn) LOSS: 0.258803 | METRIC: 0.91\n",
      "(val) LOSS: 0.688788 | METRIC: 0.9061\n",
      "EPOCH: 80 | LRs: {0.010126969480916695}\n",
      "(trn) LOSS: 0.250483 | METRIC: 0.91252\n",
      "(val) LOSS: 0.05754 | METRIC: 0.9106\n",
      "EPOCH: 81 | LRs: {0.009170984810310883}\n",
      "(trn) LOSS: 0.237602 | METRIC: 0.91818\n",
      "(val) LOSS: 0.210064 | METRIC: 0.9231\n",
      "EPOCH: 82 | LRs: {0.008257824348290657}\n",
      "(trn) LOSS: 0.222865 | METRIC: 0.9217\n",
      "(val) LOSS: 0.380698 | METRIC: 0.9182\n",
      "EPOCH: 83 | LRs: {0.007388445874081452}\n",
      "(trn) LOSS: 0.2087 | METRIC: 0.9268\n",
      "(val) LOSS: 0.203067 | METRIC: 0.9106\n",
      "EPOCH: 84 | LRs: {0.0065637612456493286}\n",
      "(trn) LOSS: 0.196417 | METRIC: 0.93276\n",
      "(val) LOSS: 0.067366 | METRIC: 0.9174\n",
      "EPOCH: 85 | LRs: {0.005784635443287945}\n",
      "(trn) LOSS: 0.184877 | METRIC: 0.93554\n",
      "(val) LOSS: 0.231262 | METRIC: 0.9168\n",
      "EPOCH: 86 | LRs: {0.005051885662373715}\n",
      "(trn) LOSS: 0.171433 | METRIC: 0.93912\n",
      "(val) LOSS: 0.252322 | METRIC: 0.927\n",
      "EPOCH: 87 | LRs: {0.004366280456240656}\n",
      "(trn) LOSS: 0.15724 | METRIC: 0.94444\n",
      "(val) LOSS: 0.098483 | METRIC: 0.9276\n",
      "EPOCH: 88 | LRs: {0.0037285389300740317}\n",
      "(trn) LOSS: 0.15229 | METRIC: 0.94682\n",
      "(val) LOSS: 0.238615 | METRIC: 0.9253\n",
      "EPOCH: 89 | LRs: {0.003139329986668441}\n",
      "(trn) LOSS: 0.136764 | METRIC: 0.9521\n",
      "(val) LOSS: 0.106109 | METRIC: 0.929\n",
      "EPOCH: 90 | LRs: {0.0025992716248410493}\n",
      "(trn) LOSS: 0.131344 | METRIC: 0.95394\n",
      "(val) LOSS: 0.196821 | METRIC: 0.9316\n",
      "EPOCH: 91 | LRs: {0.0021089302912361664}\n",
      "(trn) LOSS: 0.120464 | METRIC: 0.95812\n",
      "(val) LOSS: 0.012378 | METRIC: 0.9317\n",
      "EPOCH: 92 | LRs: {0.0016688202862010413}\n",
      "(trn) LOSS: 0.108324 | METRIC: 0.96176\n",
      "(val) LOSS: 0.048654 | METRIC: 0.9319\n",
      "EPOCH: 93 | LRs: {0.0012794032243556815}\n",
      "(trn) LOSS: 0.10515 | METRIC: 0.96326\n",
      "(val) LOSS: 0.302965 | METRIC: 0.9334\n",
      "EPOCH: 94 | LRs: {0.0009410875504229773}\n",
      "(trn) LOSS: 0.102335 | METRIC: 0.9651\n",
      "(val) LOSS: 0.010191 | METRIC: 0.9344\n",
      "EPOCH: 95 | LRs: {0.000654228110826519}\n",
      "(trn) LOSS: 0.092055 | METRIC: 0.96782\n",
      "(val) LOSS: 0.217858 | METRIC: 0.9368\n",
      "EPOCH: 96 | LRs: {0.0004191257815057318}\n",
      "(trn) LOSS: 0.088838 | METRIC: 0.96956\n",
      "(val) LOSS: 0.0185 | METRIC: 0.9359\n",
      "EPOCH: 97 | LRs: {0.00023602715233854101}\n",
      "(trn) LOSS: 0.090678 | METRIC: 0.96912\n",
      "(val) LOSS: 0.171839 | METRIC: 0.936\n",
      "EPOCH: 98 | LRs: {0.00010512426850267556}\n",
      "(trn) LOSS: 0.087549 | METRIC: 0.96992\n",
      "(val) LOSS: 0.0406 | METRIC: 0.936\n",
      "EPOCH: 99 | LRs: {2.6554429046761403e-05}\n",
      "(trn) LOSS: 0.086199 | METRIC: 0.97104\n",
      "(val) LOSS: 0.040684 | METRIC: 0.9373\n",
      "Best Val Score: 0.9373\n",
      "Runtime: 14462\n"
     ]
    }
   ],
   "source": [
    "!python train.py --logdir convratio0.625 --patch_size 2 --epochs 100 --rel_pos 1 \\\n",
    "--rel_pos_mul 0 --n_out_convs 0 --squeeze_conv 1 --linformer 0 --conv_ratio 0.625 --n_mid_convs 6 \\\n",
    "--sep_conv 0 --dim 384 --mlp_dim_mul 2 --depth 3 --heads 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
